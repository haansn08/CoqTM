\chapter{Definitions}
\label{chap:definitions}

In this chapter, we will formally define the notion of multi-tape Turing machines.  We take the Definitions of multi-tape Turing machines and their
tapes from Asperti and Ricciotti \cite{asperti2015}.  We introduce notions for specifying the semantics of machines, which are also based on Asperti
and Ricciotti \cite{asperti2015}.  We define basic machines and prove their correctness.

\section{Prelimninary Definitions}
\label{sec:prelim}


\subsection{Notational Conventions}
\label{sec:notational-conventions}

We use superscripts ($X^n$) to denote lists of fixed length (also called vectors).  Natural zero-based numbers are used as indexes for list and
vector-access ($x[i]$).  We also use standard list notations for vectors.  The symbols $\Unit$, $\Bool$, $\Type$, $\Prop$, $\Nat$, $\Option(X)$,
$X \times Y$, $X + Y$, and $\List(X)$ stand for the well-known standard types.  $\sum_{a:A} B$ denote sigma types, i.e.\ dependet pairs, with the
projections $\pi_1$ and $\pi_2$.  We write $(a,b)$ for instances of sigma types. For tuples $A = (a, b, c, \cdots)$, we use subscripts ($a_M$) for the
projections.  We usually leave subscripts out if they are clear from the context.  We use the symbols $\None$ and $\Some x$ as instances of the type
$\Option(X)$.


\subsection{Relations}
\label{sec:relations}

We define the semantics of concrete Turing machines in terms of relations.  We use the notation $R \subseteq A \times B$ to declare relations
$R : A \to B \to Prop$.  We call relations of the form $R \subseteq A \times B \times A$ \emph{partitioned relations}, that means
$R : A \to B \times A \to \Prop$.  We use lambda-notation, i.e.\ $\lambda a~b.~\cdots$, to define relations.  We write unit-partioned relations
$R \subseteq A \times \Unit \times A$ simply as relations $R \subseteq A \times A$.

We use the following standard relational operators:

\begin{definition}[Relational operators]
  Let $R, S \subseteq A \times B$ and $T \subseteq B \times C$.
  \begin{align*}
    R \cap S &:= \lam{x~y}{R~x~y \land S~x~y} \\
    R \cup S &:= \lam{x~y}{R~x~y \lor S~x~y} \\
    R \circ T &:= \lam{x~z}{\exists y.~R~x~y \land S~y~z}
  \end{align*}
\end{definition}

Note that if we compose a binary relation $R \subseteq A \times A$ with a partioned relation $S \subseteq A \times B \times A$, we get a partioned
relation $R \circ S \subseteq A \times B \times A$.

We can also define the reflexive transitive closure of binary relations, also known as relational Kleene star:

\begin{definition}[Kleene star]
  \label{def:Kleene}
  Let $R \subseteq A \times A$.  The relation $R^*$ is defined inductively:
  \[
    \inferrule{ }{R^*~x~x}
    \qquad
    \inferrule{R~x~y \and R^*~y~z}{R^*~x~z}
  \]
\end{definition}

We also have an operator that restricts the partition $B$ of a partitioned relation and yields a binary relation:

\begin{definition}[Relational restriction]
  \label{def:rel-restrict}
  Let $R \subseteq A \times B \times A$ and $y:B$.
  \[
    R \at y := \lam{x~y}{R~x~y~z}
  \]
\end{definition}

Similarly, we can define an operator that takes a binary relation and yields a partioned relation where we fix the parameter.

\begin{definition}[Relational fix]
  \label{def:rel-fix}
  Let $R \subseteq A \times A$ and $y : B$.
  \[
    R \att y := \lam{x~(y', z)}{R~x~z \land y'=y}
  \]
\end{definition}


\subsection{Retracts}
\label{sec:retracts}

Retracts are a natural way to formalise injections $f$ together with a partial inversion function $f^{-1}$.

\begin{definition}[Retract]
  \label{def:retract}
  Let $A$ and $B$ be types.  A pair of functions $f : A \to B$, $f^{-1} : B \to \Option(A)$ is called a retract if

  \begin{enumerate}
  \item $\forall x.~f^{-1}(f(x)) = \Some x$ and
  \item $\forall x~y.~f^{-1}(y) = \Some x \rightarrow y = f(x)$.
  \end{enumerate}
\end{definition}

The point \ref{def:retract} (1) means that $f^{-1}$ inverses $f$.  It is equivialent to the following commutative diagram:
\[
  \begin{tikzcd}
    A \arrow[r, "f"] \arrow[d, "\Some \cdot", swap] & B \arrow[ld, "g"] \\
    \Option(A) &
  \end{tikzcd}
\]
The second point of \ref{def:retract} means that $f^{-1}$ only maps values back that are in the image of $f$.  This property is sometimes called
\emph{tightness}.

We write $f : A \hookrightarrow B$ when we assume that the pair $(f, f^{-1})$ is a retract.


\begin{lemma}[Basic properties of retracts]
  \label{lem:retracts-basic}
  Let $f : A \hookrightarrow B$.
  \begin{enumerate}
  \item $f : A \to B$ is injective, i.e.\ $\forall x~y.~f(x)=f(y) \rightarrow x=y$.
  \item $\forall (x~y:A).~f^{-1}(f(x)) = \Some y \rightarrow x=y$.
  \item $\forall (y:B).~f^{-1}(y) = \None \rightarrow \forall (x:A).~f(x) \neq y$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  Claim (2) follows by claim (1) and \ref{def:retract} (2).  Claim (3) is a direct cosequence of \ref{def:retract} (2).

  Proof of claim (1).  Let $x, y: A$ and $f(x)=f(y)$.  We have to show $x=y$.  It is enough to show $\Some x = \Some y$.  By \ref{def:retract} (1), we
  know $\Some x = f^{-1}(f(x))$ and $\Some y = f^{-1}(f(y))$, therefore it is enough to show that $f^{-1}(f(x)) = f^{-1}(f(y))$.  This is trivial
  because we assumed $f(x)=f(y)$.
\end{proof}

\begin{definition}[Basic retracts]
  \label{def:retracts-basic}
  Let $A$ and $B$ be types.  We define the retracts $RetrId : A \hookrightarrow A$, $RetrLft : A \hookrightarrow A+B$, $RetrRgt : B \hookrightarrow A+B$:
  \begin{alignat*}{2}
    RetrId(x)  &:= x      &\qquad\qquad RetrId ^{-1} (x) &:= \Some x \\
    RetrLft(x) &:= \inl x &             RetrLft^{-1} (z) &:=
    \begin{cases}
      \Some x & z = \inl x \\
      \None   & z = \inr y
    \end{cases} \\
    RetrRgt(y) &:= \inr y & RetrRgt^{-1} (z) &:=
    \begin{cases}
      \None   & z = \inl x \\
      \Some y & z = \inr y
    \end{cases}
  \end{alignat*}
\end{definition}

\begin{definition}[Composition of retracts]
  \label{def:retract-compose}
  Let $f : A \hookrightarrow B$ and $g : B \hookrightarrow C$.  Then $f \circ g : A \hookrightarrow C$ defined as followed is a retract.
  \begin{alignat*}{2}
    & (f \circ g)      & (a) &:= g(f(a)) \\
    & (f \circ g)^{-1} & (c) &:=
                          \begin{cases}
                            \Some a & g^{-1}(c) = \Some b \land f^{-1}(b) = \Some a \\
                            \None   & \text{else}
                          \end{cases}
  \end{alignat*}
\end{definition}



% TODO: Basic retracts
% TODO: Compose retracts




\section{Machines and Tapes}
\label{sec:machine-tapes}

We use the definition of \emph{multi-tape Turing machines} and their semantics from Asperti and Ricciotti~\cite{asperti2015}.

\begin{definition}[Movement]
  \label{def:movement}
  There are three possible movements:
  $$\MS{Move} ::= L ~|~ R ~|~ N.$$
\end{definition}


\begin{definition}[Multi-tape Turing machine]
  \label{def:mTM}
  An \emph{$n$-tape Turing machine} over a finite alphabet $\Sigma$ is a tuple $M = (Q, \delta, start, halt)$ where
  \begin{itemize}
  \item $Q$ is a finite type
  \item $\delta \from Q \times (\Option~\Sigma)^n \to Q \times (\Option~\Sigma \times \MS{Move})^n$
  \item $start:Q$
  \item $halt \from Q \to \Bool$ 
  \end{itemize}
\end{definition}

We write $\MS{TM}_\Sigma^n$ for the type of $n$-tape Turing machines over the alphabet $\Sigma$.

While we parametrised Definition~\ref{def:mTM} over the alphabet $\Sigma$ and the number of tapes $n$, we hide the finite type $Q$ of \emph{states}.
The transition function $\delta$ yields for every state and vector of $n$ read symbols the new state and a vector of $n$ (optional) symbols to write,
and a direction to move.  The read symbols are optional, since it can be the case that there is no symbol under the head of a tape.  $start$ is the
start state of the machine and $halt$ represents the subset of halting states.  Tuples of the type $\Option(\Sigma) \times \Move$ are called
\emph{actions}.  They are refered to with the symbol $\MS{Act}_\Sigma$ or $\MS{Act}$ if $\Sigma$ is clear.  Our machines behave deterministically,
because $\delta$ is a function.

When we want to verify complex machines, we do not want to reason about internal states.  We rather want to reason about partitions of states, e.g.\
positive or negative states.  In general, if $F$ is a finite type, then $M = (M', part)$ is a \emph{partitioned} machine, where $M'$ is an
unpartitioned machine and $part \from Q_M \to F$ the partitioning function.  We write $\MS{TM}_\Sigma^n(F)$ for the type of partioned machines over
$F$\footnote{Formally, it could be defined as a sigma type: $\MS{TM}_\Sigma^n(F) := \sum_{M:\MS{TM}_\Sigma^n}\bigl(Q_M \to F\bigr)$}.  For brevity, we
will make no distinction between unit-partioned machines $\TM_\Sigma^n(\Unit)$ and unpartioned machines $\TM_\Sigma^n$.  We use the symbol $M$ for
both partioned and unpartitioned machines $\TM_\Sigma^n$.  It should however be always clear from the context, whether $M$ is a partitioned or
unpartitioned machine.

On a \emph{tape}, arbitrary much memory can be allocated.  However every tape has only finitely many symbols, i.e.\ there is a left-most and a
right-most symbol.  A tape essentially is a triple $(ls,m,rs)$, where the symbol $m$ is the symbol on which the (read/write) head of tape is.  It is
essential that the symbol lists are ordered such that the head of the list is the symbol next to the symbol $m$.  With other words, $ls$ is stored in
reversed order.

There are three cases where there is no current symbol: the tape can be completely empty, or the head can be to the left (or right) outermost of the
non-empty tape.  Formally, tapes are defined inductively:

\begin{definition}[Tape]
  \label{def:tape}
  Let $\Sigma$ be a finite alphabet.  Then $\Tape_\Sigma$ is defined as the inductive type:
  \begin{align*}
    & \Tape_\Sigma := \\
    & \quad | \quad \MS{niltape} \\
    & \quad | \quad \MS{leftof}  ~ (r:\Sigma) ~ (rs:\List(\Sigma)) \\
    & \quad | \quad \MS{midtape} ~ (ls:\List(\Sigma)) ~ (m:\Sigma) ~ (rs:\List(\Sigma)) \\
    & \quad | \quad \MS{rightof} ~ (l:\Sigma) ~ (ls:\List(\Sigma)).
  \end{align*}
\end{definition}

As usual, we leave the subscript $\Sigma$ out, if it is clear from the context.

% We introduce a informal notation of tapes, where the symbols are represented from left to right, hence we have to reverse the lists $ls$.  The
% position of the head is marked by the arrow:
% \begin{align*}
%   \niltape &:= \MS{niltape}\\
%   \leftof{r}{rs} &:= \MS{leftof}~r~rs\\
%   \midtape{ls}{m}{rs} &:= \MS{midtape}~(\rev~rs)~m~rs\\
%   \rightof{ls}{l} &:= \MS{rightof}~(\rev~ls)~l
% \end{align*}

Now we can define the \emph{configuration} of a multi-tape Turing machine.  It is captured by the current state and the vector of the $n$ tapes:
\begin{definition}[Configuration]
  \label{def:config}
  A \emph{configuration} of $M: \TM_\Sigma^n$ is a tuple $c = (q, t)$, where $q: Q_M$ and $t: \Tape_\Sigma^n$.  We write
  $\Conf_M := Q_M \times \Tape_\Sigma^n$ for the type of configurations of $M$.
\end{definition}

% \begin{alignat*}{2}
%   \MS{mv}_R&~(\leftof{r}{R}               &&:= \midtape{\nil}{r}{R} \\
%   \MS{mv}_R&~(\midtape{L}{m}{\nil})       &&:= \rightof{L}{m} \\
%   \MS{mv}_R&~(\midtape{L}{m}{r \cons R)}) &&:= \midtape{L \app [m]}{r}{R} \\
%   \MS{mv}_N&~(t)                          &&:= t
% \end{alignat*}
% The function $\MS{mv}_L$ is defined analogously.
The function $\MS{mv} \from \Move \to \Tape_\Sigma \to \Tape_\Sigma$ moves a tape in a direction.
\begin{definition}[Tape movement]
  \footnotesize
  \begin{alignat*}{4}
    & \MS{mv}~L~(\MS{leftof}~r~rs)               &&:= \MS{leftof}~r~rs
    &~~~&
      \MS{mv}~R~(\MS{leftof}~r~rs)               &&:= \MS{midtape}~\nil~r~rs \\
    & \MS{mv}~L~(\MS{midtape}~\nil~m~rs          &&:= \MS{leftof}~m~rs
    && \MS{mv}~R~(\MS{midtape}~ls~m~\nil         &&:= \MS{rightof}~m~ls \\
    & \MS{mv}~L~(\MS{midtape}~(l \cons ls)~m~rs  &&:= \MS{midtape}~ls~l~(m \cons rs)
    && \MS{mv}~R~(\MS{midtape}~ls~m~(r \cons rs) &&:= \MS{midtape}~(m \cons ls)~r~rs \\
    & \MS{mv}~L~(\MS{rightof}~l~ls)              &&:= \MS{midtape}~ls~l~\nil
    && \MS{mv}~R~(\MS{rightof}~l~ls)             &&:= \MS{rightof}~l~ls \\
    & \MS{mv}~\_~(\MS{niltape})                  &&:= \MS{niltape}
    && \MS{mv}~N~t                               &&:= t
  \end{alignat*}
\end{definition}
Note that moving further right (or left) when that tape already is to the right (or left) of the symbols, does not change the tape.

The functions $\MS{left},~\MS{right} \from \Tape \to \List(\Sigma)$ return the symbols to the left (or right) side of the head:
\begin{definition}[$\MS{left}$ and $\MS{right}$]
  \begin{alignat*}{4}
    \MS{left} &~(\MS{niltape})                 &&:= \nil
    \quad\quad\quad\quad
    & \MS{right}&~(\MS{niltape})               &&:= \nil \\
    \MS{left} &~(\MS{leftof}~{r}~{rs})         &&:= \nil
    & \MS{right}&~(\MS{leftof}~{r}~{rs})       &&:= r \cons rs \\
    \MS{left} &~(\MS{midtape}~{ls}~{m}~{rs})   &&:= ls
    & \MS{right}&~(\MS{midtape}~{ls}~{m}~{rs}) &&:= rs \\
    \MS{left} &~(\MS{rightof}~{l}~{ls})        &&:= l \cons ls
    & \MS{right}&~(\MS{rightof}~{l}~{ls})      &&:= \nil
  \end{alignat*}
\end{definition}

% Note that as a consequence of the informal notation, we have
% $$\MS{left}(\midtape{ls}{m}{rs}) = \MS{left}(\MS{midtape}~(\rev{ls})~{m}~{rs}) = \rev{ls}.$$

Now we can define the function $\MS{wr} \from \Tape \to \Option(\Move) \to \Tape$, that writes an optional symbol to a tape.  When we write $\None$,
the tape remains unchanged.  But if we write $\Some a$, we get a $\MS{midtape}$, where the left and right symbols remain unchanged and $a$ is now in
the middle.

\begin{definition}[$\MS{wr}$]
  \begin{alignat*}{3}
    \MS{wr}~t &~ \None   &&:= t \\
    \MS{wr}~t &~ \Some a &&:= \MS{midtape}~(\MS{left}~t)~{a}~(\MS{right}~t)
  \end{alignat*}
\end{definition}

To define the function $\MS{step} \from \Conf \to \Conf$, we need to know the symbols on the tapes.  Therefore we define a function
$\MS{current} \from Tape \to \Option(\Sigma)$.  It returns $\None$ if the pointer is not under a symbol, and $\Some a$ if the pointer is under the
symbol $a$.

\begin{definition}[$\MS{current}$]
  \begin{alignat*}{2}
    \MS{current}&~(\MS{midtape}~{ls}~{m}~{rs})&&:= \Some m \\
    \MS{current}&~\_                          &&:= \None
  \end{alignat*}
\end{definition}

We can state a correctness Lemma of the function $\MS{wr}$:

\begin{lemma}[Correctness of $\MS{wr}$]
  \label{lem:write}
  For all tapes $t$ and symbols $\sigma:\Sigma$:
  % TODO: Align it, for example like in https://tex.stackexchange.com/questions/12771/mix-align-and-enumerate
  \begin{enumerate}
  \item $\MS{right}   (\MS{wr}~t~\Some\sigma) = \MS{right}(t)$
  \item $\MS{left}    (\MS{wr}~t~\Some\sigma) = \MS{left} (t)$
  \item $\MS{current} (\MS{wr}~t~\Some\sigma) = \Some\sigma$
  \end{enumerate}
\end{lemma}
\begin{proof}
  All claims follow by case analysis over $t$.
\end{proof}

We can now define the function $\MS{step} \from \Conf \to \Conf$.  First, the machine reads all the currents symbols from the tapes.  It inserts this
vector and the current state into the transition function $\delta$.  Then, each tape writes the symbol and moves its head into the direction which
$\delta$ yielded for it.  The machine ends up in a new step $q'$.

\begin{definition}[$\MS{step}$]
  \label{def:step}
  \begin{alignat*}{2}
    \MS{doAct} &~t~(s, d) &~:=~& \MS{mv}~d~(\MS{wr}~t~s) \\
    \MS{step}  &~(q, t)   &~:=~& \Let{(q', \MS{actions}) := \delta(q, \map{\MS{current}}{t})}{ \\
               &          &~  ~& (q', \maptwo{\MS{doAct}}{\MS{tapes}}{\MS{actions}})}
  \end{alignat*}
\end{definition}

To define the execution of a machine, we first define an abstract recursive \emph{loop} function of the type
$\Loop \from (A \to A) \to (A \to \Bool) \to \Nat \to A \to \Option(A)$, for every $A:\Type$:

\begin{definition}[$\Loop$]
  \begin{align*}
    \Loop~f~h~k~s :=
    \begin{cases}
      \Some{s}                   & h(s) \\
      \None                      & \lnot h(s) \land k = 0 \\
      \Loop~f~h~(k-1)~(f~s)  & \lnot h(s) \land k > 0
    \end{cases}
  \end{align*}
\end{definition}

We can show some basic facts about $\Loop$.
\begin{lemma}[Basic facts about $\Loop$]
  \label{lem:loop}
  Let $k,l : \Nat$ and $x,s:A$.
  \begin{enumerate}
  \item \label{lem:loop_monotone}
    If $k \le l$ and $\Loop~f~h~k~s = \Some x$, then $\Loop~f~h~l~s = \Some x$.
  \item \label{lem:loop_injective}
    If $\Loop~f~h~k~s = \Some x$ and $\Loop~l~f~k~s = \Some y$, then $x = y$.
  \item \label{lem:loop_fulfills}
    If $\Loop~f~h~k~s = \Some{x}$, then $h(x) = \true$.
  \item \label{lem:loop_0}
    If $h~x = \true$, then $\Loop~f~h~k~s = \Some{s}$.
  \item \label{lem:loop_eq_0}
    If $h~s = \true$ and $\Loop~f~h~k~a = \Some{x}$, then $x=s$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  Claims~\ref{lem:loop_monotone},~\ref{lem:loop_injective}, and~\ref{lem:loop_fulfills} follow by induction on $k : \Nat$.  Claim \ref{lem:loop_0}
  follows by Definition.  Claim \ref{lem:loop_eq_0} is a direct consequence of claim \ref{lem:loop_0}.
\end{proof}


We instanciate the abstract $\Loop$ function and get a function $\MS{exec} \from \Tape^n \to \Nat \to \Option(\Conf)$ that executes $k$ steps
of the machine, given initial tapes $t: \Tape^n$:

\begin{definition}[Machine execution]
  \begin{alignat*}{3}
    \MS{initConf}   &~t         &&:= (t, start) \\
    \MS{haltConf}   &~(t, q)    &&:= halt(q) \\
    \MS{loopM}      &~c~k       &&:= \Loop~\MS{step}~\MS{haltConf}~k~c
  \end{alignat*}
\end{definition}

We write $M(c) \terminates^k c'$ for $\MS{loopM}~k~c = \Some {c'}$ and $M(t) \terminates^k c$ for $M(\MS{initConf}~t) \terminates^k c$.

All definitions, except partioned machines are from Asperti and Ricciotti \cite{asperti2015}, with similiar names.  However, the $\Loop$ function
was slightly changed for convenience, so that it needs zero steps when the (abstract) state is a halting state.

\section{Specification of Semantics}
\label{sec:spec_semantics}

We have defined big-step semantics for (partitioned) mulit-tape Turing machines.  Now we want to define predicates to specify the semantics of a
concrete (partitioned) machine $M: \TM_\Sigma^n(F)$.  It consists consists of two parts: \emph{correctness} and \emph{runtime}.

The correctness part is captured by \emph{realisation} of a (partitioned) relation $R$:

\begin{definition}[Realisation]
  \label{def:realisation}
  Let $M:\TM_\Sigma^n(F)$ and $R \subseteq \Tape_\Sigma^n \times F \times \Tape_\Sigma^n$.
  \[
    M \vDash R :=
    \forall t~k~q~t'.~M(t) \terminates^k (q, t') \rightarrow
    R~t~(\MS{part}_M~q, t')
  \]
  Where $\MS{part}_M \from Q_M \to F$ is the partitioning function of $M$.
\end{definition}

If $M \vDash R$, we say that $M$ realises the relation $R$.  Informally, this means that the output of the machine is correct (i.e.\ is in the
relation), if the machine terminates.

The runtime part of the semantics implies termination of the machine on certain inputs.  It also links the input $t:\Tape_\Sigma^n$ to the number of
steps the machine needs for the computation.

\begin{definition}[Termination on a runtime relation]
  \label{def:termination}
  Let $T \subseteq \Tape_\Sigma^n \times \Nat$.
  \[
    M \downarrow T :=
    \forall t~k.~T~t~k \rightarrow
    \exists c.~M \terminates^k c.
  \]
\end{definition}


\begin{lemma}[Monotonicity of $M \vDash R$]
  \label{lem:Realise_monotone}
  If $M \vDash R$ and $R \subseteq R'$, then $M \vDash R'$.
\end{lemma}

\begin{lemma}[Monotonicity of $M \downarrow T$]
  \label{lem:TerminatesIn_monotone}
  If $M \downarrow T$ and $T' \subseteq T$, then $M \downarrow T'$.
\end{lemma}


For machines that always terminate in a constant number of steps, it is useful to combine both predicates:
\begin{definition}[Realisation in constant time]
  \label{def:RealiseIn}
  ~
  \[
    M \vDash^k R :=
    \forall t'.~
    \exists q~t'.~
    M(t) \terminates^k(q, t') \land R~t~(part_M~q,~t')
  \]
\end{definition}

\begin{lemma}[Specification of realisation in constant time]
  \label{lem:Realise_total}
  \[
    M \vDash^k R
    \quad\iff\quad
    M \vDash R ~\land~
    M \downarrow (\lambda \_~i.~k \le i)
  \]
\end{lemma}

\begin{lemma}[Monotonicity of $M \vDash^k R$]
  \label{lem:RealiseIn_monotone}
  If $M \vDash^k R$, $k \leq k'$, and $R \subseteq R'$, then \\
  $M \vDash^{k'} R'$.
\end{lemma}

Asperti and Ricciotti \cite{asperti2015} make a distinction between weak and strong realisation, where the strong version implies termination for
every imput.  We use their weak realisation extended with the finite partition $F$.  They also have no notition of runtime.


\section{Basic Machines}
\label{sec:basic_machines}


We define several classes of \emph{basic} one-tape machines.  All complex machines we will build later, will be based on these basic machines.  In the
next chapter, I will show how to combine these basic machines and build complex machines.


\subsection{Nop}
\label{sec:basic_machines-Nop}

A very simple class of (partitioned) machine is the one-tape $\MS{Nop}$ machine.  It terminates immediately, i.e.\ after 0 steps.  For convenience, We
define $\MS{Nop}$ over a partition $f:F$, i.e.\ all states of $\MS{Nop}$ are mapped into the same partition.  We do this for all basic machines, except
$\MS{Read}$, but there is no real need to do this, since we will introduce a simple operator on partitioned machines that simply changes the partition
in Chapter~\ref{chap:combining}.
\begin{definition}[Nop]
  \label{def:Nop}
  Let $f:F$ be a partition.  $\MS{Nop}~f: \TM_\Sigma^1(F)$ is defined as follows:
  \begin{align*}
    Q          &:= \Unit \\
    start      &:= \unit \\
    \delta ~\_ &:= (\unit, \Vector{(\None, N)}) \\
    halt   ~\_ &:= \true \\
    part   ~\_ &:= f
  \end{align*}
\end{definition}
The correctness relation says exactly that the tapes don't change and that the machine terminates in $f$:
\begin{lemma}[Correctness of $\MS{Nop}$]
  \label{lem:Nop_Sem}
  ~
  \[
    \MS{Nop}~f \vDash^0 \MS{NopRel}~f.
  \]
  with
  \[
    \MS{NopRel}~f := \lambda~t~(y,t').~ t' = t \land y = f.
  \]
\end{lemma}
\begin{proof}
  By execution.  The machine terminates after zero steps in the start state.
\end{proof}

Note that the correctness relation of $\MS{Nop}$ can also be expressed using the identity relation $Id$ and the relational fix:
\[
  \MS{NopRel}~f \equiv Id \att f.
\]
However, we have the convention to define relations of concrete machine (classes) in $\lambda$-notation, i.e.\ not using relational operators.  Also
note that the tape $t'$ is per convention always on the left side of the equality.

\subsection{DoAct}
\label{sec:DoAct}

Machines of the next class, $\MS{DoAct}~a~f : \TM_\Sigma^1(F)$, do only one action $a$ and terminate in $f$ after one step.
\begin{definition}[$\MS{DoAct}~a~f$]
  \label{def:DoAct}
  Let $a:\MS{Act}$ and $f:F$.
  \begin{align*}
    Q          &:= \Bool \\
    start      &:= \false \\
    \delta ~\_ &:= (\true, \Vector{a}) \\
    halt   ~ b &:= b \\
    part   ~\_ &:= f
  \end{align*}
\end{definition}
The semantics of $\MS{DoAct}$ is easily expressed using $\MS{doAct}$ (see Definition \ref{def:step}):
\begin{lemma}[Correctness of $\MS{DoAct}$]
  \label{lem:tam}
  ~
  \[
    \MS{DoAct}~a~f \vDash^1 \MS{DoActRel}~a~f.
  \]
  with
  \[
    \MS{DoActRel}~a~f := \lambda~t~(y, t').~ t' = \MS{doAct}~t~a \land y = f.
  \]
\end{lemma}
\begin{proof}
  By execution.
\end{proof}


We define some abbreviations:

\begin{definition}[Machine classes derived from $\MS{DoAct}$]
 \label{def:DoAct-derived} 

 \begin{align*}
   \MS{Move}       ~d &:= \MS{DoAct} (\None, d) \\
   \MS{Write}    ~s   &:= \MS{DoAct} (\Some{s}, N) \\
   \MS{WriteMove}~s~d &:= \MS{DoAct} (\Some{s}, d)
 \end{align*}
 
\end{definition}



\subsection{Read}
\label{sec:basic_machines-Read}

$Read : \TM_\Sigma^1(\Option(\Sigma))$ is an interesting class of machines.  The machines of this class have one state for each character of the
alphabet.  They read one symbol and terminate in the state that corresponds to this symbol.  They have a distinct state for the case that the current
symbol is $\None$.


\begin{definition}[$\MS{Read}$]
  \begin{align*}
    F          &:= \Option(\Sigma) \\
    Q          &:= \Bool+\Sigma \\
    start      &:= \inl \false \\
    \delta (\_, s) &:=
                     \begin{cases}
                       (\inl \true, \Vector{(\None, N)}) & s[0] = \None \\
                       (\inr c, \Vector{(\None, N)})     & s[0] = \Some c
                     \end{cases} \\
    halt   ~ (\inl  b) &:= b \\
    halt   ~ (\inr \_) &:= \true \\
    part   ~ (\inl  q) &:= \None \\
    part   ~ (\inr  s) &:= \Some s
  \end{align*}
\end{definition}


\begin{lemma}[Correctness of $\MS{Read}$]
  \label{lem:Read_Sem}
  ~
  \[
    \MS{Read}~f \vDash^0 \MS{ReadRel}~f.
  \]
  where
  \[
    \MS{ReadRel} := \lambda~t~y~t'.~ y = \MS{current}~t[0] \land t' = t
  \]
\end{lemma}
\begin{proof}
  Case distinction over $\MS{current t[0]}$.  Both cases by executing the machine one step.
\end{proof}



%%% Local Variables:
%%% TeX-master: "thesis"
%%% End:
