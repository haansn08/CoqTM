\chapter{Definitions}
\label{chap:definitions}

In this chapter, we formally define the notion of multi-tape Turing machines.  We take the definition of multi-tape Turing machines and their tapes
from Asperti and Ricciotti \cite{asperti2015}.  We introduce notions for specifying the semantics of machines, which are also based on Asperti and
Ricciotti \cite{asperti2015}.  We define basic machines and prove their correctness.

\section{Preliminary Definitions}
\label{sec:prelim}


\subsection{Notational Conventions}
\label{sec:notational-conventions}

The symbols $\Unit$, $\Bool$, $\Nat$, $X \times Y$, $X + Y$, $\Option(X)$, and $\List(X)$ stand for the well-known standard types.  $\Type$ stands for
the type of types and $\Prop$ for the type of propositions.  The unit element $\unit$ is the only element of $\Unit$.  $\sum_{a:A} B(a)$ denote sigma
types, i.e.\ depended pairs, with the projections $\pi_1$ and $\pi_2$.  We write $(a,b)$ for elements of sigma types.  For tuples
$A = (a, b, c, \cdots)$, we use subscripts ($a_A$) for the projections.  We use the symbols $\None$ and $\Some x$ as elements of the type
$\Option(X)$.  $\Fin_n := \setOf{0, \dots, n-1}$ is the type with $k$ elements.  We use indices $i:\Fin_n$ for vector-access $x[i]$ with $x:X^n$,
where $X^n$ denotes the type of vectors over $X$ of size $n$.  We usually leave subscripts out if they are clear from the context.


\subsection{Relations}
\label{sec:relations}

We define the semantics of concrete Turing machines in terms of relations.  We write $R \subseteq A \times B$ as a notation for
$R : A \to B \to \Prop$.  We call relations of the form $R \subseteq A \times (B \times A)$ \emph{partitioned relations} and write
$R \subseteq A \times B \times C$.  We use lambda-notation to define relations.  We identify unit-partitioned relations
$R \subseteq A \times \Unit \times A$ with binary relations $R \subseteq A \times A$.

We use the following standard relational operators:

\begin{definition}[Relational operators]
  Let $R, S \subseteq A \times B$ and $T \subseteq B \times C$.
  \begin{align*}
    R \cap S  &:= \lambda (x~y).~R~x~y \land S~x~y \\
    R \cup S  &:= \lambda (x~y).~R~x~y \lor S~x~y \\
    R \circ T &:= \lambda (x~z).~\exists y.~R~x~y \land S~y~z
  \end{align*}
\end{definition}

Note that if we compose a binary relation $R \subseteq A \times A$ with a partitioned relation $S \subseteq A \times B \times A$, we get a partitioned
relation $R \circ S \subseteq A \times B \times A$.

We use $\bigcup_{c:A} R(c)$ as a notation for $\lambda a~b.~\exists c.~R(c)~a~b$.  We also define the reflexive transitive closure of binary
relations, also known as relational Kleene star:

\begin{definition}[Kleene star]
  \label{def:Kleene}
  Let $R \subseteq A \times A$.  The relation $R^*$ is defined inductively:
  \[
    \inferrule{ }{R^*~x~x}
    \qquad
    \inferrule{R~x~y \and R^*~y~z}{R^*~x~z}
  \]
\end{definition}

The relational power operator composes a relation $k$ times.
\begin{definition}[Relational power]
  \label{def:pow}
  Let $R \subseteq A \times A$.  The relation $R^k$ is defined inductively:
  \[
    \inferrule{ }{R^0~x~x}
    \qquad
    \inferrule{R~x~y \and R^k~y~z}{R^{(S~k)}~x~z}
  \]
\end{definition}

We have an operator that restricts the partition $B$ of a partitioned relation and yields a binary relation:
\begin{definition}[Relational restriction]
  \label{def:rel-restrict}
  Let $R \subseteq A \times B \times A$ and $y:B$.
  \[
    R \at y := \lambda(x~z).~R~x~(y,z)
  \]
\end{definition}

Similarly, we can define an operator that takes a binary relation and yields a partitioned relation where we fix the parameter.
\begin{definition}[Relational fix]
  \label{def:rel-fix}
  Let $R \subseteq A \times A$ and $y : B$.
  \[
    R \att y := \lambda x~(y', z).~R~x~z \land y'=y
  \]
\end{definition}

\begin{definition}[Relational inclusion and equivalence]
  Let $R,S \subseteq A \times B$.
  \begin{align*}
    R \subseteq S &:= \forall x~y.~R~x~y \rightarrow S~x~y \\
    R \equiv S    &:= R \subseteq S ~\land~ S \subseteq R
  \end{align*}
\end{definition}


\subsection{Retractions}
\label{sec:retracts}

Retractions are a natural way to formalise injections $f$ together with a partial inversion function $f^{-1}$.

\begin{definition}[Retraction]
  \label{def:retract}
  Let $A, B : \Type$.  A pair of functions $f : A \to B$, $f^{-1} : B \to \Option(A)$ is called a retraction between $A$ and $B$, if
  $ \forall x~y.~f^{-1}(y) = \Some x \iff y = f(x). $
\end{definition}

The direction from right to left of Definition~\ref{def:retract} means that $f^{-1}$ inverses $f$.  It is equivalent to the following commutative
diagram:
\[
  \begin{tikzcd}
    A \arrow[r, "f"] \arrow[d, "\Some \cdot", swap] & B \arrow[ld, "g"] \\
    \Option(A) &
  \end{tikzcd}
\]
The direction from left to right of Definition~\ref{def:retract} means that $f^{-1}$ only maps values back that are in the image of $f$.  This
property is called \emph{tightness}.

We write $f : A \hookrightarrow B$ when we assume that the pair $(f, f^{-1})$ is a retraction.


\begin{lemma}[Basic properties of retractions]
  \label{lem:retracts-basic}
  Let $f : A \hookrightarrow B$.
  \begin{enumerate}
  \item \label{lem:retract_g_adjoint}
    $\forall (x:A).~f^{-1}(f(x)) = \Some{x}$
  \item \label{lem:retract_g_None}
    $\forall (y:B).~f^{-1}(y) = \None \rightarrow \forall (x:A).~f(x) \neq y$
  \item \label{lem:retract_f_injective}
    $f : A \to B$ is injective, i.e.\ $\forall x~y.~f(x)=f(y) \rightarrow x=y$
  \item \label{lem:retract_g_Some}
    $\forall (x~y:A).~f^{-1}(f(x)) = \Some y \rightarrow x=y$
  \end{enumerate}
\end{lemma}

\begin{proof}
  Claim~\ref{lem:retract_g_adjoint} and ~\ref{lem:retract_g_None} are direct consequences of Definition~\ref{def:retract}.
  Claim~\ref{lem:retract_g_Some} follows by Claim~\ref{lem:retract_f_injective}.

  Proof of Claim~\ref{lem:retract_f_injective}.  Let $x, y: A$ and $f(x)=f(y)$.  We have to show $x=y$.  It is enough to show $\Some x = \Some y$.  By
  Claim~\ref{lem:retract_g_adjoint}, we know $\Some x = f^{-1}(f(x))$ and $\Some y = f^{-1}(f(y))$, therefore it is enough to show that
  $f^{-1}(f(x)) = f^{-1}(f(y))$.  This is trivial because we assumed $f(x)=f(y)$.
\end{proof}

\begin{definition}[Basic retractions]
  \label{def:retracts-basic}
  Let $A$ and $B$ be types.  We define the retractions\\
  $RetrId : A \hookrightarrow A$, $RetrLft : A \hookrightarrow A+B$, and $RetrRgt : B \hookrightarrow A+B$:
  \begin{alignat*}{2}
    RetrId(x)  &:= x      &\qquad\qquad RetrId ^{-1} (x) &:= \Some x \\
    RetrLft(x) &:= \inl x &             RetrLft^{-1} (z) &:=
    \begin{cases}
      \Some x & z = \inl x \\
      \None   & z = \inr y
    \end{cases} \\
    RetrRgt(y) &:= \inr y & RetrRgt^{-1} (z) &:=
    \begin{cases}
      \None   & z = \inl x \\
      \Some y & z = \inr y
    \end{cases}
  \end{alignat*}
\end{definition}

\begin{definition}[Composition of retractions]
  \label{def:retract-compose}
  Let $f : A \hookrightarrow B$ and $g : B \hookrightarrow C$.  Then $f \circ g : A \hookrightarrow C$ is defined as the following retraction:
  \begin{alignat*}{2}
    & (f \circ g)      & (a) &:= g(f(a)) \\
    & (f \circ g)^{-1} & (c) &:=
    \begin{cases}
      f^{-1}(b) & g^{-1}(c) = \Some{b} \\
      \None & g^{-1}(c) = \None
    \end{cases}
  \end{alignat*}
\end{definition}



\section{Machines and Tapes}
\label{sec:machine-tapes}

% There are many variations of Turing machines.  We have chosen multi-Tape

We use the definition of multi-tape Turing machines and their tapes and semantics from Asperti and Ricciotti~\cite{asperti2015}.

\begin{definition}[Movement]
  \label{def:movement}
  There are three possible movements:
  $$\MS{Move} ::= L ~|~ R ~|~ N.$$
\end{definition}


\begin{definition}[Multi-tape Turing machine]
  \label{def:mTM}
  An \emph{$n$-tape Turing machine}\footnote{Asperti and Ricciotti~\cite{asperti2015} restrict this definition to machines with $n>0$.  We do not have
    this restriction.  We actually define a $0$-tape machine $\MS{Null}$, see Section~\ref{sec:Null}.} over a finite alphabet $\Sigma$ is a tuple
  $M = (Q, \delta, start, halt)$ where
  \begin{itemize}
  \item $Q$ is a finite type
  \item $\delta \from Q \times \left(\Option(\Sigma)\right)^n \to Q \times \left(\Option(\Sigma) \times \MS{Move}\right)^n$
  \item $start:Q$
  \item $halt \from Q \to \Bool$ 
  \end{itemize}
\end{definition}

We write $\MS{TM}_\Sigma^n$ for the type of $n$-tape Turing machines over the alphabet $\Sigma$.

While we parametrised Definition~\ref{def:mTM} over the alphabet $\Sigma$ and the number of tapes $n$, we hide the finite type $Q$ of \emph{states}.
The transition function $\delta$ yields for every state and vector of $n$ read symbols the new state and a vector of $n$ (optional) symbols to write,
and a direction to move.  The read symbols are optional, since it can be the case that there is no symbol under the head of a tape.  $start$ is the
start state of the machine and $halt$ represents the subset of halting states.  Tuples of the type $\Option(\Sigma) \times \Move$ are called
\emph{actions}.  They are referred to with the symbol $\MS{Act}_\Sigma$ or $\MS{Act}$ if $\Sigma$ is clear.  Our machines behave deterministically,
because $\delta$ is a function.

When we want to verify complex machines, we do not want to reason about internal states.  We rather want to reason about partitions of states, e.g.\
positive or negative states.  In general, if $F$ is a finite type, then $M = (M', part)$ is a \emph{partitioned} machine, where $M'$ is an
unpartitioned machine and $part \from Q_M \to F$ the partitioning function.  We write $\MS{TM}_\Sigma^n(F)$ for the type of partitioned machines over
$F$\footnote{Formally, it could be defined as a sigma type: $\MS{TM}_\Sigma^n(F) := \sum_{M:\MS{TM}_\Sigma^n}\bigl(Q_M \to F\bigr)$}.  For brevity, we
will make no distinction between unit-partitioned machines $\TM_\Sigma^n(\Unit)$ and unpartitioned machines $\TM_\Sigma^n$.  We use the symbol $M$ for
both partitioned and unpartitioned machines $\TM_\Sigma^n$.  It should however be always clear from the context, whether $M$ is a partitioned or
unpartitioned machine.

On a \emph{tape}, arbitrary much memory can be allocated.  However every tape has only finitely many symbols, i.e.\ there is a left-most and a
right-most symbol.  A tape essentially is a triple $(ls,m,rs)$, where the symbol $m$ is the symbol under which the (read/write) head of tape is.  It
is convenient that the symbol lists are ordered such that the head of the list is the symbol next to the symbol $m$.  With other words, $ls$ is stored
in reversed order.

There are three cases where there is no current symbol: the tape can be completely empty, or the head can be to the left (or right) outermost of the
non-empty tape.  Formally, tapes are defined inductively:

\begin{definition}[Tape]
  \label{def:tape}
  Let $\Sigma : \Type$.  Then $\Tape_\Sigma$ is defined as the inductive type:
  \begin{align*}
    & \Tape_\Sigma ::= \\
    & \quad | \quad \MS{niltape} \\
    & \quad | \quad \MS{leftof}  ~ (r:\Sigma) ~ (rs:\List(\Sigma)) \\
    & \quad | \quad \MS{midtape} ~ (ls:\List(\Sigma)) ~ (m:\Sigma) ~ (rs:\List(\Sigma)) \\
    & \quad | \quad \MS{rightof} ~ (l:\Sigma) ~ (ls:\List(\Sigma)).
  \end{align*}
\end{definition}

As usual, we leave the subscript $\Sigma$ out, if it is clear from the context.

% We introduce a informal notation of tapes, where the symbols are represented from left to right, hence we have to reverse the lists $ls$.  The
% position of the head is marked by the arrow:
% \begin{align*}
%   \niltape &:= \MS{niltape}\\
%   \leftof{r}{rs} &:= \MS{leftof}~r~rs\\
%   \midtape{ls}{m}{rs} &:= \MS{midtape}~(\rev~rs)~m~rs\\
%   \rightof{ls}{l} &:= \MS{rightof}~(\rev~ls)~l
% \end{align*}

Now we can define the \emph{configuration} of a multi-tape Turing machine.  It is captured by the current state and the vector of the $n$ tapes:
\begin{definition}[Configuration]
  \label{def:config}
  A \emph{configuration} of $M: \TM_\Sigma^n$ is a tuple $c = (q, t)$, where $q: Q_M$ and $t: \Tape_\Sigma^n$.  We write
  $\Conf_M := Q_M \times \Tape_\Sigma^n$ for the type of configurations of $M$.
\end{definition}

% \begin{alignat*}{2}
%   \MS{mv}_R&~(\leftof{r}{R}               &&:= \midtape{\nil}{r}{R} \\
%   \MS{mv}_R&~(\midtape{L}{m}{\nil})       &&:= \rightof{L}{m} \\
%   \MS{mv}_R&~(\midtape{L}{m}{r \cons R)}) &&:= \midtape{L \app [m]}{r}{R} \\
%   \MS{mv}_N&~(t)                          &&:= t
% \end{alignat*}
% The function $\MS{mv}_L$ is defined analogously.
The function $\MS{mv} \from \Move \to \Tape_\Sigma \to \Tape_\Sigma$ moves a tape in a direction.
\begin{definition}[Tape movement]
  \footnotesize
  \begin{alignat*}{4}
    & \MS{mv}~L~(\MS{leftof}~r~rs)                &&:= \MS{leftof}~r~rs
    && \MS{mv}~R~(\MS{leftof}~r~rs)               &&:= \MS{midtape}~\nil~r~rs \\
    & \MS{mv}~L~(\MS{midtape})~\nil~m~rs          &&:= \MS{leftof}~m~rs
    && \MS{mv}~R~(\MS{midtape}~ls~m~\nil          &&:= \MS{rightof}~m~ls \\
    & \MS{mv}~L~(\MS{midtape}~(l \cons ls)~m~rs)  &&:= \MS{midtape}~ls~l~(m \cons rs)
    && \MS{mv}~R~(\MS{midtape}~ls~m~(r \cons rs)) &&:= \MS{midtape}~(m \cons ls)~r~rs \\
    & \MS{mv}~L~(\MS{rightof}~l~ls)               &&:= \MS{midtape}~ls~l~\nil
    && \MS{mv}~R~(\MS{rightof}~l~ls)              &&:= \MS{rightof}~l~ls \\
    & \MS{mv}~\_~(\MS{niltape})                   &&:= \MS{niltape}
    && \MS{mv}~N~t                                &&:= t
  \end{alignat*}
\end{definition}
Note that moving further right (or left) when that tape already is to the right (or left) of the symbols, does not change the tape.

The functions $\MS{left},~\MS{right} \from \Tape \to \List(\Sigma)$ return the symbols to the left (or right) side of the head:
\begin{definition}[$\MS{left}$ and $\MS{right}$]
  \begin{alignat*}{4}
    \MS{left} &~(\MS{niltape})                 &&:= \nil
    \quad\quad\quad\quad
    & \MS{right}&~(\MS{niltape})               &&:= \nil \\
    \MS{left} &~(\MS{leftof}~{r}~{rs})         &&:= \nil
    & \MS{right}&~(\MS{leftof}~{r}~{rs})       &&:= r \cons rs \\
    \MS{left} &~(\MS{midtape}~{ls}~{m}~{rs})   &&:= ls
    & \MS{right}&~(\MS{midtape}~{ls}~{m}~{rs}) &&:= rs \\
    \MS{left} &~(\MS{rightof}~{l}~{ls})        &&:= l \cons ls
    & \MS{right}&~(\MS{rightof}~{l}~{ls})      &&:= \nil
  \end{alignat*}
\end{definition}

% Note that as a consequence of the informal notation, we have
% $$\MS{left}(\midtape{ls}{m}{rs}) = \MS{left}(\MS{midtape}~(\rev{ls})~{m}~{rs}) = \rev{ls}.$$

Now we can define the function $\MS{wr} \from \Tape \to \Option(\Move) \to \Tape$, that writes an optional symbol to a tape.  When we write $\None$,
the tape remains unchanged.  But if we write $\Some a$, we get a $\MS{midtape}$, where the left and right symbols remain unchanged and $a$ is now in
the middle.

\begin{definition}[$\MS{wr}$]
  \begin{alignat*}{3}
    \MS{wr}~t &~ \None   &&:= t \\
    \MS{wr}~t &~ \Some a &&:= \MS{midtape}~(\MS{left}~t)~{a}~(\MS{right}~t)
  \end{alignat*}
\end{definition}

To define the function $\MS{step} \from \Conf \to \Conf$, we need to know the symbols on the tapes.  Therefore we define a function
$\MS{current} \from Tape \to \Option(\Sigma)$.  It returns $\None$ if the head is not under a symbol, and $\Some a$ if the head is under the symbol
$a$.

\begin{definition}[$\MS{current}$]
  \begin{alignat*}{2}
    \MS{current}&~(\MS{midtape}~{ls}~{m}~{rs})&&:= \Some m \\
    \MS{current}&~\_                          &&:= \None
  \end{alignat*}
\end{definition}

We can state a correctness lemma of the function $\MS{wr}$:

\begin{lemma}[Correctness of $\MS{wr}$]
  \label{lem:write}
  For all tapes $t$ and symbols $\sigma:\Sigma$:
  % TODO: Align it, for example like in https://tex.stackexchange.com/questions/12771/mix-align-and-enumerate
  \begin{enumerate}
  \item $\MS{right}   (\MS{wr}~t~\Some\sigma) = \MS{right}(t)$
  \item $\MS{left}    (\MS{wr}~t~\Some\sigma) = \MS{left} (t)$
  \item $\MS{current} (\MS{wr}~t~\Some\sigma) = \Some\sigma$
  \end{enumerate}
\end{lemma}
\begin{proof}
  All claims follow by case analysis over $t$.
\end{proof}

We can now define the function $\MS{step} \from \Conf \to \Conf$.  First, the machine reads all the currents symbols from the tapes.  It inserts this
vector and the current state into the transition function $\delta$.  Then, each tape writes the symbol and moves its head into the direction which
$\delta$ yielded for it.  The machine ends up in a new step $q'$.

\begin{definition}[$\MS{step}$]
  \label{def:step}
  \begin{alignat*}{2}
    \MS{doAct} &~t~(s, d) &~:=~& \MS{mv}~d~(\MS{wr}~t~s) \\
    \MS{step}  &~(q, t)   &~:=~& \Let{(q', \MS{actions}) := \delta(q, \map{\MS{current}}{t})}{ \\
               &          &~  ~& (q', \maptwo{\MS{doAct}}{\MS{tapes}}{\MS{actions}})}
  \end{alignat*}
\end{definition}

To define the execution of a machine, we first define an abstract recursive \emph{loop} function of the type
$\Loop \from (A \to A) \to (A \to \Bool) \to A \to \Nat \to \Option(A)$, for every $A:\Type$:

\begin{definition}[$\Loop$]
  \begin{align*}
    \Loop~f~h~a~k :=
    \begin{cases}
      \Some{a}               & h(a) \\
      \None                  & \lnot h(a) \land k = 0 \\
      \Loop~f~h~(f~a)~(k-1)  & \lnot h(a) \land k > 0
    \end{cases}
  \end{align*}
\end{definition}

We can show some basic facts about $\Loop$.
\begin{lemma}[Basic facts about $\Loop$]
  \label{lem:loop}
  Let $k,l : \Nat$ and $a,b,b':A$.
  \begin{enumerate}
  \item \label{lem:loop_monotone}
    If $k \le l$ and $\Loop~f~h~a~k = \Some{b}$, then $\Loop~f~h~a~l = \Some{b}$.
  \item \label{lem:loop_injective}
    If $\Loop~f~h~a~k = \Some{b}$ and $\Loop~f~h~a~l = \Some{b'}$, then $b = b'$.
  \item \label{lem:loop_fulfills}
    If $\Loop~f~h~a~k = \Some{b}$, then $h(b) = \true$.
  \item \label{lem:loop_0}
    If $h~a = \true$, then $\Loop~f~h~a~k = \Some{a}$.
  \item \label{lem:loop_eq_0}
    If $h~a = \true$ and $\Loop~f~h~a~k = \Some{b}$, then $a=b$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  Claims~\ref{lem:loop_monotone},~\ref{lem:loop_injective}, and~\ref{lem:loop_fulfills} follow by induction on $k : \Nat$.  Claim~\ref{lem:loop_0}
  follows by Definition.  Claim~\ref{lem:loop_eq_0} is a direct consequence of claim~\ref{lem:loop_0}.
\end{proof}


We instantiate the abstract $\Loop$ function and get a function $\MS{loopM} \from \Conf \to \Nat \to \Option(\Conf)$ that executes $k$ steps of the
machine:
\begin{definition}[Machine execution]
  \begin{alignat*}{3}
    \MS{initConf}   &~t         &&:= (t, start) \\
    \MS{haltConf}   &~(t, q)    &&:= halt(q) \\
    \MS{loopM}      &~c~k       &&:= \Loop~\MS{step}~\MS{haltConf}~c~k
  \end{alignat*}
\end{definition}

We write $M(c) \terminates^k c'$ for $\MS{loopM}~c~k = \Some {c'}$ and $M(t) \terminates^k c$ for $M(\MS{initConf}~t) \terminates^k c$.

All definitions, except partitioned machines are from Asperti and Ricciotti \cite{asperti2015}, with similar names.  However, the $\Loop$ function
was slightly changed for convenience, so that it needs zero steps when the (abstract) state is a halting state.

\section{Specification of Semantics}
\label{sec:spec_semantics}

We have defined big-step semantics for (partitioned) multi-tape Turing machines.  Now we want to define predicates to specify the semantics of a
concrete (partitioned) machine $M: \TM_\Sigma^n(F)$.  It consists consists of two parts: \emph{correctness} and \emph{runtime}.

The correctness part is captured by \emph{realisation} of a (partitioned) relation $R$:

\begin{definition}[Realisation]
  \label{def:realisation}
  Let $M:\TM_\Sigma^n(F)$ and $R \subseteq \Tape_\Sigma^n \times F \times \Tape_\Sigma^n$.
  \[
    M \Realise R :=
    \forall t~k~q~t'.~M(t) \terminates^k (q, t') \rightarrow
    R~t~(part_M~q, t')
  \]
  Where $part_M \from Q_M \to F$ is the partitioning function of $M$.
\end{definition}

If $M \Realise R$, we say that $M$ realises the relation $R$.  Informally, this means that the output of the machine is correct (i.e.\ is in the
relation), if the machine terminates.

The runtime part of the semantics implies termination of the machine on certain inputs.  It links the input $t:\Tape_\Sigma^n$ to the number of steps
the machine needs for the computation.

\begin{definition}[Termination on a runtime relation]
  \label{def:TerminatesIn}
  Let $T \subseteq \Tape_\Sigma^n \times \Nat$.
  \[
    M \TerminatesIn T :=
    \forall t~k.~T~t~k \rightarrow
    \exists c.~M (t) \terminates^k c.
  \]
\end{definition}


\begin{lemma}[Monotonicity of $M \Realise R$]
  \label{lem:Realise_monotone}
  If $M \Realise R'$ and $R' \subseteq R$, then $M \Realise R$.
\end{lemma}

\begin{lemma}[Anti-monotonicity of $M \TerminatesIn T$]
  \label{lem:TerminatesIn_monotone}
  If $M \TerminatesIn T'$ and $T \subseteq T'$, then $M \TerminatesIn T$.
\end{lemma}

For machines that always terminate in a constant number of steps, it is useful to combine both predicates:
\begin{definition}[Realisation in constant time]
  \label{def:RealiseIn}
  ~
  \[
    M \RealiseIn{k} R :=
    \forall t'.~
    \exists q~t'.~
    M(t) \terminates^k(q, t') \land R~t~(part_M~q,~t')
  \]
\end{definition}

\begin{lemma}[Specification of realisation in constant time]
  \label{lem:Realise_total}
  \[
    M \RealiseIn{k} R
    \quad\iff\quad
    M \Realise R ~\land~
    M \TerminatesIn (\lambda \_~i.~k \le i)
  \]
\end{lemma}

\begin{lemma}[Monotonicity of $M \RealiseIn{k} R$]
  \label{lem:RealiseIn_monotone}
  If $M \RealiseIn{k'} R'$, $k' \leq k$, and $R' \subseteq R$, then \\
  $M \RealiseIn{k} R$.
\end{lemma}

Asperti and Ricciotti \cite{asperti2015} make a distinction between weak and strong realisation, where the strong version implies termination for
every input, however, in an uncertain number of steps.  We use their weak realisation extended with the finite partition $F$.  They also have no
notion of runtime.


\section{Basic Machines}
\label{sec:basic_machines}

We define several classes of \emph{basic} machines.  All complex machines we build are based on these basic machines.  In the next chapter, we show
how to combine these basic machines and build complex machines.

\subsection{Null}
\label{sec:Null}

A very simple class of machine is the zero-tape $\MS{Null}$ machine.  The class $\MS{Null}_\Sigma$ is parametrised over the alphabet, however,
$\Sigma$ is always clear in the context, so we leave the index out.  We fix an alphabet $\Sigma$.  $\MS{Null}$ terminates immediately, i.e.\ after $0$
steps.

\begin{definition}[Null]
  \label{def:Null}
  $\MS{Nop}~f: \TM_\Sigma^{\mkern+1mu 0}$ is defined as follows:
  \begin{align*}
    Q          &:= \Unit \\
    start      &:= \unit \\
    \delta ~\_ &:= (\unit, \nil) \\
    halt   ~\_ &:= \true
  \end{align*}
\end{definition}
Note that if we have an unpartitioned machine $M:\TM_\Sigma^n$, we implicitly partition it over $\Unit$ with $part(q)=\unit$.

% The correctness relation says exactly that the tapes don't change:
The correctness relation is the universal relation, because empty vectors do not have information.
\begin{lemma}[Correctness of $\MS{Null}$]
  \label{lem:Null_Sem} $\MS{Null} \RealiseIn0 NullRel$ with $NullRel := \lambda~t~t'.~ \True$.
\end{lemma}
\begin{proof}
  By execution.  The machine terminates after zero steps in the start state.
\end{proof}

\subsection{DoAct}
\label{sec:DoAct}

Machines of the next class, $\MS{DoAct}~a : \TM_\Sigma^1(F)$, do only one action $a:\Act$ (i.e.\ they optionally write a symbol and move the tape) and
terminate after this step.
\begin{definition}[$\MS{DoAct}~a$]
  \label{def:DoAct}
  Let $a:\Act_\Sigma$.  Then $\MS{DoAct}~a : \TM_\Sigma^1$ is defined as follows:
  \begin{align*}
    Q          &:= \Bool \\
    start      &:= \false \\
    \delta ~\_ &:= (\true, \Vector{a}) \\
    halt   ~ b &:= b
  \end{align*}
\end{definition}
The semantics of $\MS{DoAct}$ is easily expressed using the function $\MS{doAct}$ (see Definition~\ref{def:step}):
\begin{lemma}[Correctness of $\MS{DoAct}$]
  \label{lem:DoAct_Sem} $\MS{DoAct}~a \RealiseIn1 DoActRel~a$ with
  \[
    DoActRel~a := \lambda~t~t'.~ t' = \MS{doAct}~t~a.
  \]
\end{lemma}
\begin{proof}
  By execution.
\end{proof}


We define some abbreviations:

\begin{definition}[Machine classes derived from $\MS{DoAct}$]
 \label{def:DoAct-derived} 

 \begin{align*}
   \MS{Move}       ~d &:= \MS{DoAct} (\None, d) \\
   \MS{Write}    ~s   &:= \MS{DoAct} (\Some{s}, N) \\
   \MS{WriteMove}~s~d &:= \MS{DoAct} (\Some{s}, d)
 \end{align*}
 
\end{definition}



\subsection{Read}
\label{sec:basic_machines-Read}

$Read : \TM_\Sigma^1(\Option(\Sigma))$ is an interesting class of partitioned machines.  The machines of this class have one state for each character
of the alphabet.  They read a symbol and terminate in the state that corresponds to this symbol.  They also have a distinct state for the case that
the current symbol is $\None$.

\begin{definition}[$\MS{Read}$]
  The machine $\MS{Read} : \TM_\Sigma^n(\Option(\Sigma))$ is defined as follows:
  \begin{align*}
    Q          &:= \Bool+\Sigma \\
    start      &:= \inl \false \\
    \delta (\_, s) &:=
                     \begin{cases}
                       (\inl \true, \Vector{(\None, N)}) & s[0] = \None \\
                       (\inr c, \Vector{(\None, N)})     & s[0] = \Some c
                     \end{cases} \\
    halt   ~ (\inl  b) &:= b \\
    halt   ~ (\inr \_) &:= \true \\
    part   ~ (\inl  q) &:= \None \\
    part   ~ (\inr  s) &:= \Some s
  \end{align*}
\end{definition}


\begin{lemma}[Correctness of $\MS{Read}$]
  \label{lem:Read_Sem} $\MS{Read}~f \RealiseIn{0} ReadRel~f$ with
  \[
    ReadRel := \lambda~t~y~t'.~ y = \MS{current}~t[0] \land t' = t
  \]
\end{lemma}
\begin{proof}
  Case distinction over $\MS{current t[0]}$.  Both cases by executing the machine one step.
\end{proof}



%%% Local Variables:
%%% TeX-master: "thesis"
%%% End:
