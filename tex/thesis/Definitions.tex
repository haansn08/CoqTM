\chapter{Definitions}
\label{chap:definitions}

In this chapter, we formally define multi-tape Turing machines.  We take the definition of multi-tape Turing machines and their tapes from Asperti and
Ricciotti \cite{asperti2015}.  We introduce notions for specifying correctness and time complexity of machines, where the former is also based
on~\cite{asperti2015}.

\section{Preliminary Definitions}
\label{sec:prelim}


\subsection{Notational Conventions}
\label{sec:notational-conventions}

The symbols $\Unit$, $\Bool$, $\Nat$, $X \times Y$, $X + Y$, $\Option(X)$, and $\List(X)$ stand for the well-known standard types.  $\Type$ stands for
the type of types and $\Prop$ for the type of propositions.  The unit element $\unit$ is the only element of $\Unit$.  $\sum_{a:A} B(a)$ denotes sigma
types, i.e.\ depended pairs, with the projections $\pi_1$ and $\pi_2$.  We write $(a,b)$ for elements of sigma types.  For (named) tuples
$A = (a:X,~b:Y,~c:Z)$, we use subscripts, i.e.\ $a_A$, for the projections.  We use the symbols $\None$ and $\Some x$ as elements of the type
$\Option(X)$.  $\Fin_n := \setOf{0, \dots, n-1}$ is the type with $n$ elements.  We use indices $i:\Fin_n$ for vector-access $x[i]$ with $x:X^n$,
where $X^n$ denotes the type of vectors over $X$ of size $n$.  We usually leave subscripts out if they are clear from the context.


\subsection{Relations}
\label{sec:relations}
\setCoqFilename{ProgrammingTuringMachines.TM.Relations}

We define the semantics of concrete Turing machines in terms of relations.  We write $R \subseteq A \times B$ as a notation for
$R : A \to B \to \Prop$.  We call relations of the form $R \subseteq A \times (B \times A)$ \emph{labelled relations} (labelled over $B$) and write
$R \subseteq A \times B \times A$.  We identify unit-labelled relations $R \subseteq A \times \Unit \times A$ with binary relations
$R \subseteq A \times A$.  We use $\lambda$-notation to define relations.

We use the following standard relational operators:

\begin{definition}[Relational operators]
  Let $R, S \subseteq A \times B$ and $T \subseteq B \times C$.
  \begin{align*}
    \coqlink[rintersection]{R \cap S}  &:= \lambda x~y.~R~x~y \land S~x~y \\
    \coqlink[runion]       {R \cup S}  &:= \lambda x~y.~R~x~y \lor S~x~y \\
    \coqlink[rcomp]        {R \circ T} &:= \lambda x~z.~\exists y.~R~x~y \land T~y~z
  \end{align*}
\end{definition}

Note that if we compose a binary relation $R \subseteq A \times A$ with a labelled relation $S \subseteq A \times B \times A$, we get a labelled
relation $R \circ S \subseteq A \times B \times A$.

We use $\coqlink[rUnion]{\bigcup_{c:C} R(c)}$ as a notation for $\lambda a~b.~\exists c.~R(c)~a~b$.  We also define the reflexive transitive closure
of binary relations, also known as relational Kleene star:

\begin{definition}[Kleene star][star]
  \label{def:Kleene}
  Let $R \subseteq A \times A$.  The relation $R^*$ is defined inductively:
  \[
    \inferrule{ }{R^*~x~x}
    \qquad
    \inferrule{R~x~y \and R^*~y~z}{R^*~x~z}
  \]
\end{definition}

The relational power operator composes a relation $k$ times.
\begin{definition}[Relational power][pow]
  \label{def:pow}
  Let $R \subseteq A \times A$.  The relation $R^k$ is defined inductively:
  \[
    \inferrule{ }{R^0~x~x}
    \qquad
    \inferrule{R~x~y \and R^k~y~z}{R^{(S~k)}~x~z}
  \]
\end{definition}

We have an operator that restricts the label $B$ of a labelled relation and yields a binary relation:
\begin{definition}[Relational restriction][restrict]
  \label{def:rel-restrict}
  Let $R \subseteq A \times B \times A$ and $y:B$.
  \[
    R \at y := \lambda x~z.~R~x~(y,z)
  \]
\end{definition}

Similarly, we can define an operator that takes a binary relation and yields a labelled relation where we fix the label.
\begin{definition}[Relational fix][rfix]
  \label{def:rel-fix}
  Let $R \subseteq A \times A$ and $y : B$.
  \[
    R \att y := \lambda x~(l', z).~R~x~z \land y'=y
  \]
\end{definition}

\begin{definition}[Relational inclusion and equivalence]
  Let $R,S \subseteq A \times A$.
  \begin{align*}
    \coqlink[subrel]{R \subseteq S} &:= \forall x~y.~R~x~y \rightarrow S~x~y \\
    \coqlink[eqrel] {R \equiv S}    &:= R \subseteq S ~\land~ S \subseteq R
  \end{align*}
\end{definition}


\subsection{Retractions}
\label{sec:retracts}

Retractions are a natural way to formalise injections $f$ together with their partial inversion function $f^{-1}$.

\begin{definition}[Retraction]
  \label{def:retract}
  Let $A, B : \Type$.  A pair of functions $f : A \to B$, $f^{-1} : B \to \Option(A)$ is called a retraction from $A$ to $B$, if
  $\forall x~y.~f^{-1}(y) = \Some x \iff y = f(x).$
\end{definition}

The direction from right to left of Definition~\ref{def:retract} means that $f^{-1}$ inverses $f$.  It is equivalent to the following commutative
diagram:
\[
  \begin{tikzcd}
    A \arrow[r, "f"] \arrow[d, "\Some \cdot", swap] & B \arrow[ld, "g"] \\
    \Option(A) &
  \end{tikzcd}
\]
The direction from left to right of Definition~\ref{def:retract} means that $f^{-1}$ only maps values back that are in the image of $f$.  This
property is called \textit{tightness}.

We write $f : A \hookrightarrow B$ when we assume that the pair $(f, f^{-1})$ is a retraction.  Note that this notation introduces two names for
functions ($f : A \to B$ and $f^{-1} : B \to \Option(A)$), but mostly we use the name $f$ for the \textit{tuple} of both functions.


\begin{lemma}[Basic properties of retractions]
  \label{lem:retracts-basic}
  Let $f : A \hookrightarrow B$.
  \begin{enumerate}
  \item \label{lem:retract_g_adjoint}
    $\forall (x:A).~f^{-1}(f(x)) = \Some{x}$
  \item \label{lem:retract_g_None}
    $\forall (y:B).~f^{-1}(y) = \None \rightarrow \forall (x:A).~f(x) \neq y$
  \item \label{lem:retract_f_injective}
    $f : A \to B$ is injective, i.e.\ $\forall x~y.~f(x)=f(y) \rightarrow x=y$
  \item \label{lem:retract_g_Some}
    $\forall (x~y:A).~f^{-1}(f(x)) = \Some y \rightarrow x=y$
  \end{enumerate}
\end{lemma}

\begin{proof}
  Claim~\ref{lem:retract_g_adjoint} and~\ref{lem:retract_g_None} are direct consequences of Definition~\ref{def:retract}.
  Claim~\ref{lem:retract_g_Some} follows by Claim~\ref{lem:retract_f_injective}.

  Proof of Claim~\ref{lem:retract_f_injective}.  Let $x, y: A$ and $f(x)=f(y)$.  We have to show $x=y$.  It is enough to show $\Some x = \Some y$.  By
  Claim~\ref{lem:retract_g_adjoint}, we know $\Some x = f^{-1}(f(x))$ and $\Some y = f^{-1}(f(y))$, therefore it is enough to show that
  $f^{-1}(f(x)) = f^{-1}(f(y))$.  This is trivial because we assumed $f(x)=f(y)$.
\end{proof}

\begin{definition}[Basic retractions]
  \label{def:retracts-basic}
  Let $A$ and $B$ be types.  We define the retractions\\
  $RetrId : A \hookrightarrow A$, $RetrLft : A \hookrightarrow A+B$, and $RetrRgt : B \hookrightarrow A+B$:
  \begin{alignat*}{2}
    RetrId(x)  &:= x      &\qquad\qquad RetrId ^{-1} (x) &:= \Some x \\
    RetrLft(x) &:= \inl x &             RetrLft^{-1} (z) &:=
    \begin{cases}
      \Some x & z = \inl x \\
      \None   & z = \inr y
    \end{cases} \\
    RetrRgt(y) &:= \inr y & RetrRgt^{-1} (z) &:=
    \begin{cases}
      \None   & z = \inl x \\
      \Some y & z = \inr y
    \end{cases}
  \end{alignat*}
\end{definition}

\begin{definition}[Composition of retractions]
  \label{def:retract-compose}
  Let $g : B \hookrightarrow C$ and $f : A \hookrightarrow B$.  Then $g \circ f : A \hookrightarrow C$ is defined as the following retraction:
  \begin{alignat*}{2}
    & (g \circ f)      & (a) &:= g(f(a)) \\
    & (g \circ f)^{-1} & (c) &:=
    \begin{cases}
      f^{-1}(b) & g^{-1}(c) = \Some{b} \\
      \None & g^{-1}(c) = \None
    \end{cases}
  \end{alignat*}
\end{definition}



\section{Machines and Tapes}
\label{sec:machine-tapes}

\setCoqFilename{ProgrammingTuringMachines.TM.TM}

% There are many variations of Turing machines.  We have chosen multi-Tape

We use the definition of multi-tape Turing machines and their tapes and semantics from Asperti and Ricciotti~\cite{asperti2015}.

\begin{definition}[Multi-tape Turing machine][mTM]
  \label{def:mTM}
  An $n$-tape Turing machine%
  \footnote{Asperti and Ricciotti~\cite{asperti2015} restrict this definition to machines with $n>0$.  We do not have this restriction.  We actually
    define a $0$-tape machine $\MS{Null}$, see Section~\ref{sec:Null}.} %
  over a finite alphabet $\Sigma$ is a tuple $M = (Q, \delta, start, halt)$ where
  \begin{itemize}
  \item $Q$ is a finite type
  \item $\delta \from Q \times \left(\Option(\Sigma)\right)^n \to Q \times \left(\Option(\Sigma) \times \MS{Move}\right)^n$
  \item $start:Q$
  \item $halt \from Q \to \Bool$ 
  \end{itemize}
  There are three possible movements: $\coqlink[move]{\MS{Move}} ::= L ~|~ R ~|~ N.$
\end{definition}

We write $\MS{TM}_\Sigma^n$ for the type of $n$-tape Turing machines over the alphabet $\Sigma$.

While we parametrise Definition~\ref{def:mTM} over the alphabet $\Sigma$ and the number of tapes $n$, we abstract the finite type $Q$ of states inside
the type of Turing machines.  The transition function $\delta$ yields for every state and vector of $n$ read symbols the new state and a vector of $n$
(optional) symbols to write, and a direction to move.  The read symbols are also optional, since it can be the case that there is no symbol under the
head of a tape.  $start$ is the start state of the machine and $halt$ represents the subset of halting states.  Tuples of the type
$\Option(\Sigma) \times \Move$ are called \textit{actions}.  They are referred to with the symbol $\MS{Act}_\Sigma$ or $\MS{Act}$ if $\Sigma$ is
clear.  Our machines behave deterministically, because $\delta$ is a function.

When we want to verify complex machines, we do not want to reason about \textit{concrete machine states}, because the number of states of a machine
could be huge.  Reasoning about \textit{all} states of a machine is thus unfeasible.  We still need to reason about states, but we do not need to
distinct most of the states.  We introduce the notion of \textbf{labelled machines}.  A label could be, for example, the type $\Bool$.  Then we only
distinct between two kinds of states.  If $L$ is a finite type, then $M = (M', lab)$ is a labelled machine, where $M'$ is an unlabelled machine and
$lab : Q_{M'} \to L$ is called the \textit{labelling function} of $M$.  The value of $lab$ is irrelevant for non-terminating states.  The function
$lab$ partitions the terminating states.  This means that all terminating states with the same label can be seen semantically equivalent.  We write
$\MS{TM}_\Sigma^n(L)$ for the type of labelled machines over $L$.\footnote{Formally, the type is defined as a sigma type:
  $\MS{TM}_\Sigma^n(L) := \sum_{M:\MS{TM}_\Sigma^n}\bigl(Q_M \to L\bigr)$.  We use the projections $\pi_1$ and $\pi_2$ implicitly.}  We identify
unit-labelled machines $\TM_\Sigma^n(\Unit)$ with unlabelled machines $\TM_\Sigma^n$.  We use the symbol $M$ for both labelled and unlabelled machines
$\TM_\Sigma^n$.  It should however be always clear from the context, whether $M$ is a labelled or unlabelled machine.

On a \emph{tape}, arbitrarily much memory can be allocated.  However every tape has only finitely many symbols, i.e.\ there is a left-most and a
right-most symbol.  A tape essentially is a triple $(ls,m,rs)$, where the symbol $m$ is the symbol under which the (read/write) head of tape is.  It
is essential that the symbol lists ($ls$ and $rs$) are ordered such that the head of the list is the symbol next to the symbol $m$.  When we think of
tapes as a finite sequence of symbols from left to right, this means that $ls$ is stored in reversed order.

There are three cases where there is no current symbol: the tape can be completely empty, or the head can be to the left (or right) outermost of a
non-empty tape.  Formally, tapes are defined inductively:

\begin{definition}[Tape][tape]
  \label{def:tape}
  Let $\Sigma : \Type$.  Then $\Tape_\Sigma$ is defined as the inductive type:
  \begin{alignat*}{2}
    & \Tape_\Sigma &~::=~& \MS{niltape} \\
    &&& |~ \MS{leftof}  ~ (r:\Sigma) ~ (rs:\List(\Sigma)) \\
    &&& |~ \MS{midtape} ~ (ls:\List(\Sigma)) ~ (m:\Sigma) ~ (rs:\List(\Sigma)) \\
    &&& |~ \MS{rightof} ~ (l:\Sigma) ~ (ls:\List(\Sigma)).
  \end{alignat*}
\end{definition}

Recall that we leave the subscript $\Sigma$ out, if it is clear from the context.

% We introduce a informal notation of tapes, where the symbols are represented from left to right, hence we have to reverse the lists $ls$.  The
% position of the head is marked by the arrow:
% \begin{align*}
%   \niltape &:= \MS{niltape}\\
%   \leftof{r}{rs} &:= \MS{leftof}~r~rs\\
%   \midtape{ls}{m}{rs} &:= \MS{midtape}~(\rev~rs)~m~rs\\
%   \rightof{ls}{l} &:= \MS{rightof}~(\rev~ls)~l
% \end{align*}

Now we can define the \emph{configuration} of a multi-tape Turing machine.  It is captured by the current state and the vector of the $n$ tapes:
\begin{definition}[Configuration][mconfig]
  \label{def:config}
  A configuration of $M: \TM_\Sigma^n$ is a tuple $c = (q, t)$, where $q: Q_M$ and $t: \Tape_\Sigma^n$.  We write
  $\Conf_M := Q_M \times \Tape_\Sigma^n$ for the type of configurations of $M$.
\end{definition}

% \begin{alignat*}{2}
%   \MS{mv}_R&~(\leftof{r}{R}               &&:= \midtape{\nil}{r}{R} \\
%   \MS{mv}_R&~(\midtape{L}{m}{\nil})       &&:= \rightof{L}{m} \\
%   \MS{mv}_R&~(\midtape{L}{m}{r \cons R)}) &&:= \midtape{L \app [m]}{r}{R} \\
%   \MS{mv}_N&~(t)                          &&:= t
% \end{alignat*}
% The function $\MS{mv}_L$ is defined analogously.
The function $\MS{mv} \from \Move \to \Tape_\Sigma \to \Tape_\Sigma$ moves a tape in a direction.
\begin{definition}[Tape movement][tape_move]
  \footnotesize
  \begin{alignat*}{4}
    & \MS{mv}~L~(\MS{leftof}~r~rs)                &&:= \MS{leftof}~r~rs
    && \MS{mv}~R~(\MS{leftof}~r~rs)               &&:= \MS{midtape}~\nil~r~rs \\
    & \MS{mv}~L~(\MS{midtape}~\nil~m~rs)          &&:= \MS{leftof}~m~rs
    && \MS{mv}~R~(\MS{midtape}~ls~m~\nil)         &&:= \MS{rightof}~m~ls \\
    & \MS{mv}~L~(\MS{midtape}~(l \cons ls)~m~rs)  &&:= \MS{midtape}~ls~l~(m \cons rs)
    && \MS{mv}~R~(\MS{midtape}~ls~m~(r \cons rs)) &&:= \MS{midtape}~(m \cons ls)~r~rs \\
    & \MS{mv}~L~(\MS{rightof}~l~ls)               &&:= \MS{midtape}~ls~l~\nil
    && \MS{mv}~R~(\MS{rightof}~l~ls)              &&:= \MS{rightof}~l~ls \\
    & \MS{mv}~\_~(\MS{niltape})                   &&:= \MS{niltape}
    && \MS{mv}~N~t                                &&:= t
  \end{alignat*}
\end{definition}
Note that moving further right (or left) when that tape already is to the right (or left) of the symbols, does not change the tape.

The functions $\MS{left},~\MS{right} \from \Tape \to \List(\Sigma)$ return the symbols to the left (or right) side of the head:
\begin{definition}[$\MS{left}$ and $\MS{right}$][left]
  \begin{alignat*}{4}
    \MS{left} &~(\MS{niltape})                 &&:= \nil
    \quad\quad\quad\quad
    & \MS{right}&~(\MS{niltape})               &&:= \nil \\
    \MS{left} &~(\MS{leftof}~{r}~{rs})         &&:= \nil
    & \MS{right}&~(\MS{leftof}~{r}~{rs})       &&:= r \cons rs \\
    \MS{left} &~(\MS{midtape}~{ls}~{m}~{rs})   &&:= ls
    & \MS{right}&~(\MS{midtape}~{ls}~{m}~{rs}) &&:= rs \\
    \MS{left} &~(\MS{rightof}~{l}~{ls})        &&:= l \cons ls
    & \MS{right}&~(\MS{rightof}~{l}~{ls})      &&:= \nil
  \end{alignat*}
\end{definition}

% Note that as a consequence of the informal notation, we have
% $$\MS{left}(\midtape{ls}{m}{rs}) = \MS{left}(\MS{midtape}~(\rev{ls})~{m}~{rs}) = \rev{ls}.$$

Now we can define the function $\MS{wr} \from \Tape_\Sigma \to \Option(\Sigma) \to \Tape_\Sigma$, that writes an optional symbol to a tape.  When we
write $\Some a$, we get a $\MS{midtape}$, where the left and right symbols remain unchanged and $a$ is now in the middle.  For $\None$, the tape
remains unchanged.  Note that there is no way to decrease the number of symbols on a tape, or to write ``blank'' symbols.

\begin{definition}[$\MS{wr}$][tape_write]
  \begin{alignat*}{3}
    \MS{wr}~t &~ \None   &&:= t \\
    \MS{wr}~t &~ \Some a &&:= \MS{midtape}~(\MS{left}~t)~{a}~(\MS{right}~t)
  \end{alignat*}
\end{definition}

To define the function $\MS{step} \from \Conf \to \Conf$, we need to know the symbols on the tapes.  Therefore we define a function
$\MS{current} \from Tape \to \Option(\Sigma)$.  It returns $\None$ if the head is not under a symbol, and $\Some m$ if the head is under the
symbol~$m$.

\begin{definition}[$\MS{current}$][current]
  \begin{alignat*}{2}
    \MS{current}&~(\MS{midtape}~{ls}~{m}~{rs})&&:= \Some m \\
    \MS{current}&~\_                          &&:= \None
  \end{alignat*}
\end{definition}

We can state a correctness lemma of the function $\MS{wr}$:

\begin{fact}[Correctness of $\MS{wr}$]
  \label{lem:write}
  For all tapes $t$ and symbols $a:\Sigma$:
  % TODO: Align it, for example like in https://tex.stackexchange.com/questions/12771/mix-align-and-enumerate
  \begin{enumerate}
  \item $\MS{right}   (\MS{wr}~t~\Some a) = \MS{right}(t)$
  \item $\MS{left}    (\MS{wr}~t~\Some a) = \MS{left} (t)$
  \item $\MS{current} (\MS{wr}~t~\Some a) = \Some a$
  \end{enumerate}
\end{fact}
% \begin{proof}
%   All claims follow by case analysis over $t$.
% \end{proof}

We can now define the function $\MS{step} \from \Conf \to \Conf$.  First, the machine reads all the current symbols from the tapes.  It inserts this
vector and the machine state into the transition function $\delta$.  Then, each tape writes the symbol and moves its head into the direction that
$\delta$ yielded for it.  The machine ends up in a new state $q'$.

\begin{definition}[$\MS{step}$][step]
  \label{def:step}
  \begin{alignat*}{2}
    \MS{doAct} &~t~(s, d) &~:=~& \MS{mv}~d~(\MS{wr}~t~s) \\
    \MS{step}  &~(q, t)   &~:=~& \Let{(q', act) := \delta(q, \map{\MS{current}}{t})}{ \\
               &          &~  ~& (q', \maptwo{\MS{doAct}}{t}{act})}
  \end{alignat*}
\end{definition}

To define the execution of a machine, we first define an abstract recursive function
$\Loop \from (A \to A) \to (A \to \Bool) \to A \to \Nat \to \Option(A)$ (for every $A:\Type$):

\setCoqFilename{ProgrammingTuringMachines.TM.Prelim}
\begin{definition}[$\Loop$][loop]
  \begin{align*}
    \Loop~f~h~a~k :=
    \begin{cases}
      \Some{a}               & h(a) \\
      \None                  & \lnot h(a) \land k = 0 \\
      \Loop~f~h~(f~a)~(k-1)  & \lnot h(a) \land k > 0
    \end{cases}
  \end{align*}
\end{definition}

We can show some basic facts about $\Loop$.
\begin{lemma}[Basic facts about $\Loop$]
  \label{lem:loop}
  Let $k,l : \Nat$ and $a,b,c:A$.
  \begin{enumerate}
  \item \label{lem:loop_monotone}
    \coqlink[loop_monotone]{If $k \le l$ and $\Loop~f~h~a~k = \Some{b}$, then $\Loop~f~h~a~l = \Some{b}$.}
  \item \label{lem:loop_injective}
    \coqlink[loop_injective]{If $\Loop~f~h~a~k = \Some{b}$ and $\Loop~f~h~a~l = \Some{c}$, then $b = c$.}
  \item \label{lem:loop_fulfills}
    \coqlink[loop_fulfills]{If $\Loop~f~h~a~k = \Some{b}$, then $h(b) = \true$.}
  \item \label{lem:loop_0}
    \coqlink[loop_0]{If $h~a = \true$, then $\Loop~f~h~a~k = \Some{a}$.}
  \item \label{lem:loop_eq_0}
    \coqlink[loop_eq_0]{If $h~a = \true$ and $\Loop~f~h~a~k = \Some{b}$, then $a=b$.}
  \end{enumerate}
\end{lemma}
\begin{proof}
  Claims~\ref{lem:loop_monotone},~\ref{lem:loop_injective}, and~\ref{lem:loop_fulfills} follow by induction on $k : \Nat$.  Claim~\ref{lem:loop_0}
  follows by Definition.  Claim~\ref{lem:loop_eq_0} is a direct consequence of claim~\ref{lem:loop_0}.
\end{proof}
\setCoqFilename{ProgrammingTuringMachines.TM.TM}


We instantiate the abstract $\Loop$ function and get a function $\MS{loopM} \from \Conf \to \Nat \to \Option(\Conf)$ that executes $k$ steps of the
machine:
\begin{definition}[Machine execution][loopM]
  \begin{alignat*}{3}
    \MS{initConf}   &~t         &&:= (t, start) \\
    \MS{haltConf}   &~(t, q)    &&:= halt(q) \\
    \MS{loopM}      &~c~k       &&:= \Loop~\MS{step}~\MS{haltConf}~c~k
  \end{alignat*}
\end{definition}

We write $M(c) \terminates^k c'$ for $\MS{loopM}~c~k = \Some {c'}$ and $M(t) \terminates^k c$ for $M(\MS{initConf}~t) \terminates^k c$.

All definitions, except labelled machines, are from Asperti and Ricciotti \cite{asperti2015}, with similar names.  However, the $\Loop$ function was
slightly changed for convenience, so that it needs zero steps when the (abstract) starting state is a halting state.

\section{Specification of Semantics}
\label{sec:spec_semantics}

We have defined semantics for multi-tape Turing machines.  Now we want to define predicates to specify the semantics of a concrete machine
$M: \TM_\Sigma^n(L)$.  There are two parts of the semantics: \emph{correctness} and \emph{time complexity}.

The correctness part is captured by realisation of a (labelled) relation $R$:

\begin{definition}[Realisation][Realise]
  \label{def:realisation}
  Let $M:\TM_\Sigma^n(L)$ and $R \subseteq \Tape_\Sigma^n \times L \times \Tape_\Sigma^n$.
  \[
    M \Realise R :=
    \forall t~k~q~t'.~M(t) \terminates^k (q, t') \rightarrow
    R~t~(lab_M~q, t')
  \]
  Where $lab_M \from Q_M \to L$ is the labelling function of $M$.
\end{definition}

If $M \Realise R$, we say that $M$ realises the relation $R$.  Informally, this means that the output of the machine is correct w.r.t.\ the relation,
if the machine terminates.

To show realisation, e.g.\ $M \Realise R$, it suffices to find a (smaller) relation $R'$ and show that it implies the (target) relation $R$:
\begin{lemma}[Monotonicity of $M \Realise R$][Realise_monotone]
  \label{lem:Realise_monotone}
  If $M \Realise R'$ and $R' \subseteq R$, then $M \Realise R$.
\end{lemma}

The running time part of the semantics implies termination of the machine on certain inputs.  It links the input $t:\Tape_\Sigma^n$ to the number of
steps that the machine needs for the computation.

\begin{definition}[Termination in a running time relation][TerminatesIn]
  \label{def:TerminatesIn}
  Let $T \subseteq \Tape_\Sigma^n \times \Nat$.
  \[
    M \TerminatesIn T :=
    \forall t~k.~T~t~k \rightarrow
    \exists c.~M (t) \terminates^k c.
  \]
\end{definition}

Termination is anti-monotone.  This means that it suffices for showing $M \downarrow T$ to find a (bigger) relation $T'$ and show $T \subseteq T'$.
\begin{lemma}[Anti-monotonicity of $M \TerminatesIn T$][TerminatesIn_monotone]
  \label{lem:TerminatesIn_monotone}
  If $M \TerminatesIn T'$ and $T \subseteq T'$, then $M \TerminatesIn T$.
\end{lemma}

For machines that always terminate in a constant number of steps, it is useful to combine both predicates:
\begin{definition}[Realisation in constant time][RealiseIn]
  \label{def:RealiseIn}
  ~
  \[
    M \RealiseIn{k} R := \forall t'.~ \exists q~t'.~ M(t) \terminates^k(q, t') \land R~t~(lab_M~q,~t')
  \]
\end{definition}

\begin{lemma}[][Realise_total]
  \label{lem:Realise_total}
  $M \RealiseIn{k} R ~\iff~ M \Realise R ~\land~ M \TerminatesIn (\lambda \_~k'.~k \le k')$
\end{lemma}

\begin{lemma}[Monotonicity of $M \RealiseIn{k} R$][RealiseIn_monotone]
  \label{lem:RealiseIn_monotone}
  If $M \RealiseIn{k'} R'$, $k' \leq k$, and $R' \subseteq R$, then \\
  $M \RealiseIn{k} R$.
\end{lemma}

Asperti and Ricciotti~\cite{asperti2015} make a distinction between weak and strong realisation, where the strong version implies termination for
every input, however, in an uncertain number of steps.  We use a variant of their weak realisation.  They have no notion of time complexity.  Because
we do not want to reason about concrete machine states, we introduced the notion of labelled machines.  The idea to label the states of machines with
elements of a finite type is due to Y.~Forster.  He also invented the realisation of labelled relations and the notion for time complexity.

\section{Canonical Relations}
\label{sec:canonical}

\enlargethispage{0.5cm}

Similar as in Asperti and Ricciotti~\cite{asperti2015}, we can define correctness relations that every machine realises.  Trivially, every machine
realises the universal relation $Univ := \lambda t~(l,t').~\True$.  Every non-terminating (diverging) machine can only realise the empty relation
$Empty := \lambda t~(l,t').~\False$.  The \textit{canonical relation} is the smallest relation that every machine realises:

\begin{fact}[Canonical correctness][Canonical_Realise]
  Let $M : \TM_\Sigma^n(L)$, then
  \[
    M \Realise \left( \lambda t~(l,t').~\exists q~k.~M(t) \terminates^k (q,t') \land lab_M(q) = l \right)
  \]
\end{fact}

Dually, every machine terminates in the empty relation.  The canonical termination relation is the biggest relation in that every machine terminates:
\begin{fact}[Canonical termination][Canonical_TerminatesIn]
  Let $M : \TM_\Sigma^n$, then $M \TerminatesIn \left( \lambda t~k.~\exists c.~M(t) \terminates^k c \right)$.
\end{fact}



%%% Local Variables:
%%% TeX-master: "thesis"
%%% End:
