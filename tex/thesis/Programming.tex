\chapter{Programming Turing Machines}
\label{chap:programming}

We can define machines using primitive operations like $\MS{DoAct}$, and can combine machines in an imperative programming style.  Furthermore, we can
reuse machines in bigger contexts.  However, our imperative ``language'' still has no notion of values or data cells.  We want to use each tape as a
data cell to store one value.  Therefore, we have to define what it means that a tape contains a value.  When we ``program'' Turing machines, instead
of using basic machines, we only use machines that directly change the value of a tape.  We use the combinators introduced in
Chapter~\ref{chap:combining} to simulate control flow of imperative programming languages.  Using the definition of value-containing, we specify a
``callee-saving'' convention for function computation.  We present a generic pattern how to program and verify Turing machines, and present more
complex case studies.


\section{Value-Containing}
\label{sec:value-containing}

We first want to define what it means that a tape $t$ \emph{contains} a value $x$, written as $t \simeq x$.  Tapes, as defined in \ref{def:tape}, are
essentially a list of symbols, so we have to linearise values to strings.

\begin{definition}[Encodable types]
  We say that a type $X$ is \emph{encodable} over $\Sigma$, if there is a function $encode : X \to \List(\Sigma)$.
\end{definition}

Morally, the encoding functions should be injective and there also should be a decoding function, such that the encoding and decoding functions is a
retraction on $\List(\Sigma)$.  However, we do not need this strict definition.

We may encode a type $X$ on any alphabet $\Tau$, if $\Sigma$ is a retraction on $\Tau$:
\begin{definition}[Map encodings]
  \label{def:Encode_map}
  Let $X$ be encodable over $\Sigma$ and $f : \Sigma \hookrightarrow \Tau$ be a retraction.  Then $X$ is also encodable over $\Tau$ with the following
  encoding function:
  \[ encode_\Tau(x) := encodeMap~encode_\Sigma~f~(x) := \map{f}{(encode_\Sigma(x))}. \]
\end{definition}

Mapping of encodings are compatible with composition of retractions.  This means that if we map the encoding twice, this is the same as mapping the
encoding with the composition of both retractions:
\begin{lemma}[Composition and encoding mapping]
  \label{lem:Encode_map_comp}
  Let $f : \Sigma \hookrightarrow \Tau$ and $g : \Tau \hookrightarrow \Delta$ be retractions and $X$ be encodable over $\Sigma$.  Then there is only
  one way how $X$ can be encoded over $\Delta$, i.e.:
  \[ encodeMap~(encodeMap~f~encode)~g~(x) = encodeMap~encode~(f \circ g)~x. \]
\end{lemma}

For each type and type constructor, we have a distinct alphabet.  We define basic encodings:
\begin{definition}[Basic encodings]
  \label{def:basic-encodings}
  ~
  \begin{enumerate}
  \item We encode $\Unit$ over the empty alphabet $\False$:
  \[ encode~\unit := \nil
  \]
  \item The types $\Bool$ and $\Fin_k$ are encoded over them-self, i.e.\ $encode(x):=[x]$.
  \item Let $X$ be encodable over $\Sigma_X$.  Then $\Option(X)$ is encodable over
    \[ \Sigma_{\Option(X)} ::= \MS{NONE} ~|~ \MS{SOME} ~|~ (x:\Sigma_X) \]
    With the retraction $RetrOpt : \Sigma_X \hookrightarrow \Sigma_{\Option(X)}$ and
    \begin{alignat*}{3}
      &encode~&&\None  &~:=~& [\MS{NONE}] \\
      &encode~&&\Some x&~:=~& \MS{SOME} \cons encode(x)
    \end{alignat*}
  \item Let $X$ be encodable over $\Sigma_X$ and $Y$ over $\Sigma_Y$.  Then $X+Y$ is encodable over
    \[ \Sigma_{X+Y} ::= \MS{INL} ~|~ \MS{INR} ~|~ (x:\Sigma_X) ~|~ (y:\Sigma_Y) \] With the retractions
    $RetrInl : \Sigma_X \hookrightarrow \Sigma_{X+Y}$, $RetrLft : \Sigma_X \hookrightarrow \Sigma_{X+Y}$ and
    \begin{alignat*}{3}
      &encode~&&(\inl x)&~:=~& \MS{INL} \cons encode(x) \\
      &encode~&&(\inr y)&~:=~& \MS{INR} \cons encode(y)
    \end{alignat*}
  \item Let $X$ be encodable over $\Sigma_X$ and $Y$ over $\Sigma_Y$.  Then $X \times Y$ is encodable over
    \[ \Sigma_{X \times Y} ::= (x:\Sigma_X) ~|~ (y:\Sigma_Y) \] With the retractions
    $RetrFst : \Sigma_X \hookrightarrow \Sigma_{X \times Y}$, $RetrSnd : \Sigma_Y \hookrightarrow \Sigma_{X \times Y}$ and
    \[
      encode(x,y) := encode(x) \app encode(y)
    \]
  \item Let $X$ be encodable over $\Sigma_X$.  Then $\List(X)$ is encodable over
    \[ \Sigma_{\List(X)} ::= \MS{NIL} ~|~ \MS{CONS} ~|~ (x:\Sigma_X) \]
    With the retraction $RetrList : \Sigma_X \hookrightarrow \Sigma_{\List(X)}$ and
    \begin{alignat*}{3}
      &encode~&&(\nil      ) &~:=~& [\MS{NIL}] \\
      &encode~&&(l \cons ls) &~:=~& \MS{CONS} \cons encode(x) \app encode(ls)
    \end{alignat*}
  \item Natural numbers $\Nat$ are encodable over $\Sigma_\Nat ::= \MS{S} ~|~ \MS{0} $ with
    \begin{alignat*}{3}
      &encode~&&(0  ) &~:=~& [\MS{O}] \\
      &encode~&&(S~n) &~:=~& \MS{S} \cons encode(n)
    \end{alignat*}
  \end{enumerate}
  Note that we implicitly map the encoding functions in this definition.
\end{definition}

This are all encodings we need.  However, there is still a problem about ambiguity: Suppose $X$ is encodable over $\Sigma$.  Then the smallest
alphabet on which we can encode the type $X+X$ is $\Tau := SigSum~\Sigma~\Sigma$.  However, now there are two possibilities how to encode $X$ on
$\Tau$: using the retraction $RetrSigX$ and $RetrSigY$.  We must deal with this problem, when we program and prove Turing machines, by explicitely
giving the right retractions.

If $X$ is encodable over $\Sigma$, we encode values of $x$ on tapes with an extended alphabet $\Sigma^+$ that has an additional start and stop symbol.
\begin{definition}[$\Sigma^+$] Let $\Sigma$ be an alphabet.
  \[
    \Sigma^+ ::= \MS{START} ~|~ \MS{STOP} ~|~ \MS{UNKNOWN} ~|~ (s: \Sigma)
  \]
  Also, we define the retraction $RetrPlus : \Sigma \hookrightarrow \Sigma^+$.
\end{definition}
The $\MS{UNKNOWN}$ symbol is important later. We define what $t \simeq x$ means:
\begin{definition}[$t \simeq x$]
  \label{def:tape_contains}
  Let $X$ be encodable over $\Sigma$ and $t : \Tape_{\Sigma^+}$.
  \[
    t \simeq x := \exists~ls.~
    t = \MS{midtape}~ls~(\MS{START})~(encode(x) \app [\MS{STOP}])
  \]
  In case the encoding is not clear, we write $t \simeq_{f} x$ with $t:\Tape_{\Tau^+}$ and $x:X$, when $X$ is encodable on $\Sigma$ according to
  Definition~\ref{def:basic-encodings}, and we map this encoding to $\Tau$ using the retraction $f: \Sigma \hookrightarrow \Tau$.
\end{definition}

Note that in Definition~\ref{def:tape_contains}, we have to map the encoding of $x$ to the extended alphabet $\Sigma^+$.  If $t \simeq x$, the head of
$t$ stands on the start symbol.  To the right, there is the encoding terminated by the stop-symbol.  To the left of the head, there may be arbitrary
many ``rest'' symbols.

We find the convention useful, that there are no further symbols beyond the stop symbol.  In future work we also want to reason about space usage of
machines.  If a tape contains a value, the size of the tape (i.e.\ the number of symbols on it), only depends on the length of the encoding and the
number of rest symbols $ls$ to the left.  We have the convention to only add symbols to the left of a tape.  We also only write on tapes, if the head
of the tape is on the right-most symbol.

\begin{definition}[Right tape]
  \label{def:isRght}
  A tape $t$ is \emph{right}, if $\MS{current}(t) \neq \None$ and $\MS{left}~t=\nil$.  With other words, $t = \MS{midtape}~ls~m~\nil$ for some
  $m:\Sigma$ and $ls:\List(\Sigma)$.
\end{definition}

\section{Alphabet-Lifting}
\label{sec:LiftAlphabet-UNKNOWN}

In Section~\ref{sec:sigma-Lift}, we defined the alphabet-lift operator.  However, we noted that we need a semantically relevant default symbol in the
``smaller'' alphabet $\Sigma$.  All ``programmed'' Turing machines are defined over an extended alphabet $\Sigma^+$.  Therefore, we use the
$\MS{UNKNOWN}$ symbol as the default symbol.  Intuitively, nothing can go wrong, because, by definition, $\MS{UNKNOWN}$ is not part of any encoding.
This intuition is confirmed by the following lemma:
\begin{lemma}[$surject$ and value-containing]
  \label{lem:contains_translate_tau}
  Let $f: \Sigma \hookrightarrow \Tau$ be a retraction between two alphabets.  Let $x:X$, where $X$ is encodable over $\Sigma$. Then, for
  $t:\Tape_\Tau$
  \[
    t \simeq_f x \iff mapTape~(surject~f)~t \simeq x.
  \]
\end{lemma}
Note that the encoding on the left side is mapped with the retraction $f$.

We write $\LiftAlphabet{M}{f}$ for $\LiftAlphabet{M}{(f, \MS{UNKNOWN})}$.  Note that we also use the $\Uparrow$ notation for the tapes-lift.  However,
it is always clear whether we mean the tape-lift or alphabet-lift.  We use the notation $\LiftBoth{M}{f}{I} := \LiftTapes{(\LiftAlphabet{M}{f})}{I}$,
for first applying the alphabet-lift, and after that the tapes-lift.

\section{Value-Manipulating Machines}
\label{sec:value-manipulate}

We defined what it means that a tape contains a value.  Now we want to define machines that manipulate values, e.g.\ increase or increase a number.
Also, a very useful operation is to copy a value from one tape to another tape.

\subsection{Write Value}
\label{sec:WriteValue}

We define a wrapper around the machine class $\MS{WriteString}$ from Section~\ref{sec:WriteString}.  Instead of a string $str : \Sigma^+$, the machine
$\MS{WriteValue}~str : \TM_{\Sigma^+}^1$ gets an encoding $str:\List(\Sigma)$ of a value as parameter.%
\footnote{The reason why $\MS{WriteValue}$ is not parametrised over values $x:X$ is, that we would also need to parametrise $\MS{WriteString}$ over
  the encoding function of $X$.}%
\begin{definition}[$\MS{WriteValue}$]
  \label{def:WriteValue}
  Let $str:\List(\Sigma)$
  \[
    \MS{WriteValue}(x) := \MS{WriteString}~L~\left(\rev{\left(\MS{START} \cons str \app [\MS{STOP}]\right)}\right).
  \]
  Note that we implicitly map $str$ to the extended alphabet $\Sigma^+$.
\end{definition}
The machine writes the stop symbol, the encoding $str$, and the start symbol in reversed order from right to left.  If it started with a right tape,
then after the execution the tape contains the value $x$ that has the encoding $str$.
\begin{lemma}[Correctness of $\MS{WriteValue}$]
  \label{lem:WriteValue_Sem}
  Let $X$ be encodable over $\Sigma$ and $str : \List(\Sigma)$.
  \[
    \MS{WriteValue}(str) \RealiseIn{3 + 2 \cdot \length{str}} WriteValueRel(str)
  \]
  \[
    WriteValueRel(str) := \lambda t~t'. \forall (x:X).~encode(x) = str \rightarrow isRight(t[0]) \rightarrow t'[0] \simeq x.
  \]
\end{lemma}


\subsection{Constructors and Deconstructors}
\label{sec:constructors-deconstructors}


For each encodable type $X:\Type$, there is a set of machines: constructors and a matching machine.  These are machines over the least alphabet
$\Sigma^+$ to encode $X$ on.  Constructor machines, informally, ``apply'' a constructor of the inductive type $X$ to the value on the tape $t[0]$.
For example, considering the inductive type $\Nat$, the constructor machine $\MS{O}$ writes the number $0$ to a right tape.  The constructor machine
$\MS{S}$ assumes that $t[0]$ contains a number $n$, and increases that number.  The deconstructor for $\Nat$ reads a number of $t[0]$.  If it is $0$,
it terminates in $\false$.  Else, it decreases the number and terminates in $\true$.  In general, we have a constructor machine for each constructor
of the inductive type.  If the constructor has additional parameters, these are encodes on more input tapes $t[1], t[2], \cdots$.  On the other side,
the deconstructor machine has a partition for each constructor and may have additional tapes for storing additional parameters.

\subsubsection{Natural numbers}
\label{sec:match-nat}

This is the correctness relation for $\MS{MatchNat}$:
\begin{definition}[Correctness relation of $\MS{MatchNat}$]
  \label{def:MatchNat_Rel}
  ~
\begin{lstlisting}[style=semicoqstyle]
$MatchNatRel :=$
  $\lambda t~(y, t').$
    $\forall (n:\Nat).$
      $t[0] \simeq n \rightarrow$
      match $y$, $n$
      [$\false$, $O$ => $t'[0] \simeq 0$
      |$\true$, $S~n'$ => $t'[0] \simeq n'$
      | _, _ => $\False$
      ].
\end{lstlisting}
\end{definition}

Note that in the case that $n$ is $0$, we could also write $t'=t$.  However we have the convention, when the tapes not change, to use the weaker
proposition that the tape $t'$ still contains the same values, and that the same tapes are right.  We have to write more, however, when we apply the
alphabet-lift with the retraction $f$, we would otherwise get assumptions like $mapTape~(surject~f)~t' = mapTape~(surject~f)~t$.  This means that we
would have to apply a lemma to show that $t'[0]$ still contains $0$, which we get for free using this convention.

Initially, the tape $t[0]$ contains some number $n$.  So the head of $t[0]$ must be on the start symbol.  The machine moves one step right and reads
the first symbol of the encoding.  This symbol may either be $\MS{S}$ or $\MS{O}$.  If the machine reads $\MS{O}$, this means that the number $n$ is
$0$, so the machine moves back to the start symbol and terminates in the partition $\false$, indicating that the number was $0$.  On the other side,
if the machine reads $\MS{S}$, this means the number $n$ is the successor of some number $n'$.  To decrement $n$, it overwrites the current $\MS{S}$
with a new start symbol and terminates on this symbol in the partition $\true$.

\begin{definition}[$\MS{MatchNat}$]
  \label{def:MatchNat}
  ~
\begin{lstlisting}[style=semicoqstyle]
$\MS{MatchNat} :=$
  Move R; 
  Match ($\MS{ReadChar}$) 
        ($\lambda(o:\Option(sigNat)).$ match $o$
           [$\Some {\MS{S}}$ => $\Return{(\MS{Write}~\MS{START})}{\true}$
           |$\Some {\MS{O}}$ => $\Return{(\MS{Move}~L)}{\false}$
           | _ => _ 
           ]).
\end{lstlisting}
\end{definition}

Note, that the placeholder $\_$ stands for some unspecified machine, e.g.\ in this case $\Return{\Nop}{b}$ where $b:\Bool$ is arbitrary.  This part of
the machine is not explicitly given, because the premise of the correctness relation of $\MS{MatchNat}$ guaranties that there must be a symbol under
the head which is either $\MS{S}$ or $\MS{O}$, so this part of the machine must never execute.

\begin{lemma}[Correctness of $\MS{MatchNat}$]
  $\MS{MatchNat} \RealiseIn{5} MatchNatRel$.
\end{lemma}
\begin{proof}
  We know that $t[0] \simeq n$.  This means $t[0] = \MS{midtape}~ls~\MS{START}~(\MS{S}^n \app \MS{O} \cons \MS{STOP})$ for some $ls$.  The proof is
  mechanical, like the above correctness proofs.
\end{proof}

We define the $O$-constructor with $\MS{WriteValue}$:
\begin{definition}[$\MS{ConstrO}$]
  \label{def:Constr_O}
  $\MS{ConstrO} := \MS{WriteValue}~[\MS{O}]$.
\end{definition}
\begin{lemma}[Correctness of $\MS{ConstrO}$]
  \label{lem:Constr_O_Sem}
  $\MS{ConstrO} \RealiseIn{5} ConstrORel$ with
  \[
    ConstrORel := \lambda t~t'.~isRight~t[0] \rightarrow t'[0] \simeq 0.
  \]
\end{lemma}
\begin{proof}
  With Lemma~\ref{lem:RealiseIn_monotone} and~\ref{lem:WriteValue_Sem}.
\end{proof}

The $S$ constructor overwrites the current symbol (which is the start symbol) with $\MS{S}$ and writes a new start symbol.
\begin{definition}[$\MS{ConstrS}$]
  $\MS{ConstrS} := \MS{WriteMove}~\MS{S}~L \Seq \MS{Write}~\MS{START}$
\end{definition}
\begin{lemma}[Correctness of $\MS{ConstrS}$]
  $\MS{ConstrS} \RealiseIn{3} ConstrSRel$ with
  \[
    ConstrSRel := \lambda t~t'.~\forall n.~ t[0] \simeq n \rightarrow t'[0] \simeq S~n.
  \]
\end{lemma}


\subsubsection{Sum Types}
\label{sec:match-sum}

Let $X$ be encodable over $\Sigma_X$ and $Y$ over $\Sigma_Y$.  $\MS{MatchSum} : \TM_{\left(SigSum~\Sigma_X~\Sigma_Y\right)^+}^1(\Bool)$ reads a value
$s:X+Y$.  If it is $\inl x$ (or $\inr~y$), it replaces the $\MS{INL}$ (or $\MS{INR}$) symbol with a new start symbol and terminates in $\true$ (or
$\false$).

\begin{definition}[$\MS{MatchSum}$]
  \label{def:MatchSum}
  ~
  \small
\begin{lstlisting}[style=semicoqstyle]
$\MS{MatchSum} :=$
  Move R; 
  Match ($\MS{ReadChar}$) 
        ($\lambda(o:\Option(sigSum~\Sigma_X~\Sigma_Y)).$ match $o$
           [$\Some {\MS{INL}}$ => $\Return{(\MS{Write}~\MS{START})}{\true}$
           |$\Some {\MS{INR}}$ => $\Return{(\MS{Write}~\MS{START})}{\false}$
           | _ => _ 
           ]).
\end{lstlisting}
\end{definition}

\begin{lemma}[Correctness of $\MS{MatchSum}$]
  \label{lem:MatchSum_Realise}
  $\MS{MatchSum} \RealiseIn{5} MatchSumRel$ with
\begin{lstlisting}[style=semicoqstyle]
$MatchSumRel :=$
  $\lambda t~(y, t').$ $\forall (s:X+Y).$ $t[0] \simeq s \rightarrow$ match $y$, $s$
      [$\false$, $\inl x$ => $t'[0] \simeq x$
      |$\true$, $\inr y$ => $t'[0] \simeq y$
      | _, _ => $\False$
      ].
\end{lstlisting}
\end{lemma}

We have one constructor machine for $\inl$ and $\inr$.  They are both analogous.  They overwrite the start symbol with $\MS{INL}$ or $\MS{INR}$ and
write a new start symbol on step further left.
\begin{definition}[$\MS{ConstrInl}$]
  \label{def:Constr_inl}
  $\MS{ConstrInl} := \MS{WriteMove}~\MS{INL}~L \Seq \MS{Write}~\MS{START}$.
\end{definition}
\begin{lemma}[Correctness of $\MS{ConstrInl}$]
  \label{lem:Constr_inl_Sem}
  $\MS{ConstrInl} \RealiseIn{3} ConstrInlRel$ with
  \[
    ConstrInlRel := \lambda t~t'.~\forall(x:X).~t[0] \simeq x \rightarrow t'[0] \simeq \inl x
  \]
\end{lemma}

\subsubsection{Option Types}
\label{sec:match-option}

The types $\Option(X)$ and $X+\Unit$ are isomorphic.  Furthermore, the alphabets to encode these types on, $SigOpt~\Sigma$ and $SigSum~\Sigma~\False$,
are also isomorphic.  We can use this fact to derive a match machine and constructor machines for the type $\Option(X)$.  Let
$f : SigSum~\Sigma~\False \hookrightarrow SigOpt~\Sigma$ be the canonical retraction.  Then, we can define $\MS{MatchOption}$ as
$\LiftAlphabet{\MS{MatchSum}}{f}$.  However, in the case that $o=\None$, the surjected output tape $t'$ contains $\unit$.  Thus, the tape has form
(for some $ls$)
\[ t' = \MS{midtape}~ls~\MS{START}~[\MS{STOP}]. \] However, we want that the tape is right in this case.  That is because $\Option(X)$ is not a
recursive data type and the information that $o=\None$ is already encoded in the partition in which $\MS{MatchOption}$ terminates.  So in this case,
the tape moves one step to the right:
\begin{definition}[$\MS{MatchOption}$]
  \label{def:MatchOption}
  ~
  \[
    \MS{MatchOption} := \If{\LiftAlphabet{\MS{MatchSum}}{f}}{\Return{\Nop}{\true}}{\Return{(\MS{Move}~R)}{\false}}.
  \]
\end{definition}

\begin{lemma}[Correctness of $\MS{MatchOption}$]
  \label{lem:MatchSum_Realise}
  $\MS{MatchOption} \RealiseIn7 MatchOptionRel$ with
\begin{lstlisting}[style=semicoqstyle]
$MatchOptionRel :=$
  $\lambda t~(y, t').$ $\forall (o:\Option(X)).$ $t[0] \simeq o \rightarrow$ match $y$, $o$
      [false, $\None$ => $isRight(t'[0])$
      |true, $\Some x$ => $t'[0] \simeq x$
      |_, _ => $\False$
      ].
\end{lstlisting}
\end{lemma}
Note that we have to add $2$ extra steps: one for the conditional and one for the $\MS{Move}$ in the $\None$-case.

We can also derive the $\Some{\cdot}$ constructor of $\Option(X)$ from the $\inl$ constructor of $X+\Unit$.
\begin{definition}[$\MS{ConstrSome}$]
  \label{def:Constr_Some}
  $\MS{ConstrSome} := \LiftAlphabet{\MS{ConstrInl}}{f}$
\end{definition}
\begin{lemma}[Correctness of $\MS{ConstrSome}$]
  \label{lem:Constr_Some_Sem}
  $\MS{ConstrSome} \RealiseIn{3} ConstrSomeRel$ with
  \[
    ConstrSomeRel := \lambda t~t'.~\forall(x:X).~t[0] \simeq x \rightarrow t'[0] \simeq \Some{x}
  \]
\end{lemma}
For the $\None$ constructor, we simply use $\MS{WriteValue}$
\begin{definition}[$\MS{ConstrNone}$]
  \label{def:Constr_None}
  $\MS{ConstrNone} := \MS{WriteValue}~[\MS{NONE}]$
\end{definition}
\begin{lemma}[Correctness of $\MS{ConstrNone}$]
  \label{lem:Constr_None_Sem}
  $\MS{ConstrNone} \RealiseIn{3} ConstrNoneRel$ with
  \[
    ConstrNoneRel := \lambda t~t'.~isRight~t[0] \simeq x \rightarrow t'[0] \simeq \None
  \]
\end{lemma}

\todo{More Matches and Constructors, e.g.\ lists, pairs etc.  Only informal description and correctness relations.}


\subsection{Copy Values}
\label{sec:copy}

In Section~\ref{sec:CopySymbols}, we defined a machine that copies symbols until a certain symbol from one tape to another tape.  In
Section~\ref{sec:MoveToSymbol}, we also defined a machine that moves the head to a certain symbol.  We want to use these machines to define a machine
that copies a value from tape $t[0]$ to tape $t[1]$.  By the convention we set up in Section~\ref{sec:value-containing}), if we write new symbols to a
tape, this tape must be right.  With other words, the machine $\MS{CopySymbols}$ can assume that the ``target'' tape is right.  Formally, the
correctness relation is defined as:
\begin{definition}[Correctness relation of $\MS{CopyValue}$]
  \label{def:CopyValue_Rel}
  ~
  \[
    CopyValueRel := \lambda t~t'. \forall (x:X).~t[0] \simeq x \rightarrow isRight~t[1] \rightarrow t'[0] \simeq x \land t'[1] \simeq x.
  \]
% \begin{lstlisting}[style=semicoqstyle]
% CopyValueRel :=
%   $\lambda t~t.\forall (x:X).$
%     $t[0] \simeq x \rightarrow$
%     $isRight t[1] \rightarrow$
%     $t'[0] \simeq x \land$
%     $t'[1] \simeq x.$
% \end{lstlisting}
\end{definition}

The algorithm of $\MS{CopyValue}$ works as follows.  First, the machine moves the head of tape $0$ to right, from the start symbol to the stop symbol.
Then it copies the symbols, from the stop symbol to the start symbol, to tape $1$.

\begin{definition}[$\MS{CopyValue}$]
  \label{def:CopyValue}
  ~
  \begin{multline*}
    \MS{CopyValue} := \\
    \LiftTapes{(\MS{MoveToSymbol}~(\lambda x. x=\MS{STOP})~~id)}{\Vector{0}}
    \Seq
    \MS{CopySymbolsL}~(\lambda x. x=\MS{START})
  \end{multline*}
\end{definition}

Note that the second parameter of $\MS{MoveToSymbol}$ is the a translation function.  In this case, it should simply move around leave the symbols
unchanged.

\begin{lemma}[Correctness of $\MS{CopyValue}$]
  \label{lem:CopyValue_Realise}
  $\MS{CopyValue} \Realise CopyValueRel$.
\end{lemma}

The proof of Lemma~\ref{lem:CopyValue_Realise} is technical.  We have several lemmas about the functions $CopySymbolFun$ and $MoveToSymbolFun$, and
the corresponding runtime functions.

The runtime of $\MS{CopyValue}$ is linear in size of the encoding of $x$.
\begin{lemma}[Runtime of $\MS{CopyValue}$]
  \label{lem:CopyValue_TerminatesIn}
  ~
  \[
    \MS{CopyValue} \TerminatesIn (\lambda t~k.~\exists(x:X).~t[0] \simeq x \land 25 + 12 \cdot \size{x} \leq k).
  \]
\end{lemma}

Although $\MS{CopyValue}$ terminates for all tapes, we restricted runtime relations to reasonable tapes, i.e.\ in this case tape vectors $t$ that
actually have a symbol on $t[0]$.  The reason for that is, that we want to relate the value to the runtime.

\subsection{Translate Values}
\label{sec:Translate}

In Section~\ref{sec:value-containing}, we observed, that the containing relation is ambiguous: if $X$ is minimally encodable over $\Sigma$, there may
be two retractions $f_1, f_2 : \Sigma \hookrightarrow \Tau$ on the alphabet $\Tau$.  In Section~\ref{sec:MoveToSymbol}, we gave the
$\MS{MoveToSymbol}$ machine the feature to translate the symbols it read.  Using this feature, we define a machine that translates between the two
possibilities of the encoding of $X$ on $\Tau$.  Therefore we have to define a function $tanslate : \Tau^+ \to \Tau^+$.

\begin{definition}[Translation between two encodings]
  \label{def:translate}
  Let $f_1, f_2 : \Sigma \hookrightarrow \Tau$ be two retractions on $\Tau$.
  \begin{alignat*}{2}
    & translate~f_1~f_2~(\tau) &~:=~&
    \begin{cases}
      f_2(\sigma)  & f_1^{-1}(\tau) = \Some{\sigma} \\
      \MS{UNKNOWN} & f_1^{-1}(\tau) = \None
    \end{cases} \\
    & translate~f_1~f_2~(\tau) &~:=~& \tau \qquad\text{(if $\tau \in \{\MS{UNKNOWN}, \MS{START}, \MS{STOP}\}$)} 
  \end{alignat*}
\end{definition}

This function translates a symbol of $\Tau$ to $\Sigma$, using the partial inversion function $f_1^{-1}$ and afterwards applies the injection $f_2$
from $\Sigma$ to $\Tau$ and the (implicit) injection from $\Tau$ to $\Tau^+$.

\begin{definition}[$\MS{Translate}$]
  ~
  \begin{alignat*}{2}
    & \MS{Translate}~f_1~f_2 &~:=~& \MS{MoveToSymbol}~(\lambda x.~x=\MS{STOP})~(translate~f_1~f_2) \Seq \\
    &                        &~  ~& \MS{MoveToSymbolL}~(\lambda x.~x=\MS{START})~id.
  \end{alignat*}
\end{definition}

\begin{lemma}[Correctness of $\MS{Translate}$]
  $\MS{Translate}~f_1~f_2 \Realise TranslateRel~f_1~f_2$ with
  \[
    TranslateRel~f_1~f_2 := \lambda t~t'.~\forall(x:X).~t[0] \simeq_{f_1} x \rightarrow t[0] \simeq_{f_2} x.
  \]
\end{lemma}


\subsection{Reset Tapes}
\label{sec:reset-tape}

The aforementioned machine $\MS{MoveToSymbol}~(\lambda x.~x=\MS{STOP})~id$ can also be used to ``reset'' a tape.  This means that if the tape contains
a value, after the execution of this machine, the tape is right.  This is especially important to prevent memory leaks in loops, where we may want to
write on a tape multiple times.  We must reset each ``used'' tape before writing on it again.

\begin{definition}[$\MS{ResetTape}$]
  \label{def:Reset}
  $\MS{ResetTape} := \MS{MoveToSymbol}~(\lambda x.~x=\MS{STOP})~id$
\end{definition}

\begin{lemma}[Correctness of $\MS{ResetTape}$]
  $\MS{ResetTape} \Realise ResetTapeRel$ with
  \[
    ResetTapeRel := \lambda t~t'.~\forall(x:X).~t[0] \simeq x \rightarrow isRight(t'[0]).
  \]
\end{lemma}


\section{Extending Alphabets}
\label{sec:extend-alphabet}

Consider that we have a machines $M_1 : \TM_{\Sigma_X}^{n_1}, M_2 : \TM_{\Sigma_Y}^{n_1}$ that operate on values of type $X$ and $Y$, where $X$ is
encodable over $\Sigma_X$ and $Y$ over $\Sigma_Y$.  Then, we could combine this machines using sequential composition and the alphabet-lift and
tapes-lift, to a machine $M : \TM_\Sigma^{n_1+n_2}$.  However, the choice of $\Sigma$ is relevant.  For example, we could chose
$\Sigma := \Sigma_X + \Sigma_Y$.  If another machine $M' : \TM_{\Sigma'}^m$ ``uses'' $M$, it has to give a retraction
$f : \Sigma_X+\Sigma_Y \hookrightarrow \Sigma'$.  However, there is a problem of generality:
\begin{fact}
  Not for all $X, Y, Z : \Type$, if there is a retraction $f_1 : X \hookrightarrow Z$ and $f_2 : Y \hookrightarrow Z$, there is a retraction
  $f_1+f_2 : X+Y \hookrightarrow Z$.
\end{fact}
\begin{proof}
  There is no injective function $\Unit+\Unit\to\Unit$.
\end{proof}

That means that we have to show a precondition to combine two retractions $f_1 : \Sigma_X \hookrightarrow \Sigma'$ and
$f_2 : \Sigma_Y \hookrightarrow \Sigma'$ and get a retraction $f_1+f_2 : \Sigma_X + \Sigma_Y \hookrightarrow \Sigma'$:
\begin{fact}
  If the retractions $f_1 : X \hookrightarrow Z$ and $f_2 : Y \hookrightarrow Z$ have disjoint images, then we can define a retraction
  $f_1+f_2 : X+Y \hookrightarrow Z$.
\end{fact}

We could live with the restriction that we have to show that the retractions have disjoint images.  However, this approach does not scale good when we
have to add more alphabets and retractions, we have to show that all retractions have disjoint images.  It seems to be easier and more general, to
define a class of machines $M$ parametrised over the alphabet $\Sigma'$ and the two retractions $f_1$ and $f_2$.  In the definition of $M$, we apply
the tapes-lift on $M_1$ and $M_2$ with the retractions $f_1$ and $f_2$.



\section{Designing Machines}
\label{sec:programming-design}

As noted above, when we speak of ``programming'' Turing machines, we mean that we use tapes as registers, and use the combinators and lift to compose
machines.  Moreover, we only use machines that directly change the values of registers (tapes).  We have machines that do a case-distinction on
values, and machines that apply constructors to the value that a tape contains.

Our $\While$ operator corresponds to ``do-while'' in imperative languages, i.e.\ the machine $M$ has to decide at the end of its execution whether to
continue or break out of the loop.  Tail-recursive functions can easily be transformed into ``do-while'' loops.  Therefore, when we translate
functions to Turing machines, we first have to implement the function as a tail-recursive function, which is then translated to a Turing machine in
``programming style''.

The ``matching'' machines do a case-distinction over the value on a tape.  They may alter the content of the tape.  Therefore, if we use ``matching''
machines inside a loop, we can not restore the value of the tape before the loop.  We have to copy the value of the tape and only work on the copy.
After that, the ``internal tape'' is reseted, so we can use the tape again without a memory leak.

% When we define and prove the semantical properties machines, we break the machine down to parts and verify each part independently.  For example, if
% we have a machine $\While~\MS{Step}$, then we first have to encode the loop-invariant into the relation $StepRel$.

We make an informal distinction between input, output, and internal tapes.  Each kind of tapes have an invariant, which is encoded in the correctness
relations of machines.  For input tapes, we have the invariant that they contain a value, and this value does not change during the execution.  Output
tapes are initially right, and contain an output value after the execution.  Internal tapes are right before and after the execution.  With this
distinction of input, output, and internal tapes, we can formalise a convention for functional computation of binary functions: Tapes $t[0]$ and
$t[1]$ are input tapes for $x$ and $y$, $t[2]$ is the output tape for $f~x~y$, and all other tapes are internal tapes.
\begin{definition}[Functional computation correctness relation]
  \label{def:Computes2_Rel}
  Let $f : X \to Y \to Z$, where $X$ and $Y$ are encodable on $\Sigma$.  Then
  $FunRel(f) \subseteq \Tape_{\Sigma^+}^{3+n} \times \Tape_{\Sigma^+}^{3+n}$ is defined as:
  \begin{alignat*}{2}
     FunRel(f) &:= \lambda t~t'.~\forall (x:X)~(y:Y). \\
    &\qquad t[0] \simeq x \rightarrow t[1] \simeq y \rightarrow \\
    &\qquad isRight~t[2] \rightarrow \\
    &\qquad \left(\forall (i:\Fin_n).~isRight~t[3+i] \right) \rightarrow \\
    &\qquad t[0] \simeq x ~\land~ t[1] \simeq y \rightarrow ~\land~ \\
    &\qquad t[2] \simeq f~x~y ~\land~ \\
    &\qquad \left(\forall (i:\Fin_n).~isRight~t'[3+i] \right).
  \end{alignat*}
  We say that a machine $M$ computes the function $f$, if $M \Realise f$.
\end{definition}

Similarly, we can define the runtime function of such a machine.
\begin{definition}[Functional computation runtime relation]
  \label{def:Computes2_T}
  Let $steps : X \to Y \to \Nat$ , where $X$ and $Y$ are encodable on $\Sigma$.  Then $FunT(h) \subseteq \Tape_{\Sigma^+} \times \Nat$ is defined as:
  \begin{alignat*}{2}
     FunT(steps) &:= \lambda t~k.~\exists (x:X)~(y:Y). \\
    &\qquad t[0] \simeq x ~\land~ t[1] \simeq y ~\land~ \\
    &\qquad isRight~t[2] ~\land~ \\
    &\qquad \left(\forall (i:\Fin_n).~isRight~t[3+i] \right) ~\land~ \\
    &\qquad steps~x~y \leq k
  \end{alignat*}
\end{definition}

Note that these definitions can be generalised to unary or functions with higher arity.  Also note that the preconditions encoded within $FunRel(f)$
and $FunT(f)$ coincide, however, with swapped quantifiers.

Internal tapes may be used to copy input-values on, if they need to be changed, e.g.\ for loops.  Thus, the general design for implementing a machine
$M$ that computes a binary function $f$, is the following:
\begin{align*}
  M := & \LiftTapes{\MS{CopyValue}}{\Vector{0; 3}} \Seq \LiftTapes{\MS{CopyValue}}{\Vector{1; 4}} \Seq \\
       & \LiftTapes{\MS{WriteValue}~\cdots}{\Vector{\cdots}} \Seq \\
       & \LiftTapes{\MS{Loop}}{\Vector{3; 4; 2; 5; 6; 7; \cdots}} \Seq \\
       & \LiftTapes{\MS{Reset}}{\Vector{3}} \Seq \LiftTapes{\MS{Reset}}{\Vector{4}} \Seq \LiftTapes{\MS{Reset}}{\Vector{5}} \Seq \cdots
\end{align*}
with $\MS{Loop} := \While(\MS{Step})$.  $\MS{Step}$ is partitioned over $\Option(\Unit)$, $\Some\unit$ means to break out of the loop and $\None$ to
continue.  Note that the $\MS{Step}$ and $\MS{Loop}$ have only ``access'' to the copies of $x$ and $y$, but not to the ``original'' on $t[0]$ and
$t[1]$ of $M$.  This also means that $\MS{Step}$ has two tapes less than $M$.  The copy of $x$ and $y$ is on the $0$st and $1$st tape of $\MS{Step}$,
the output is on tape $2$, all further tapes are internal tapes.  Before the loop, some tapes may be initialised with values.  After the loop, all
tapes that $\MS{Step}$ did not reset, including the tapes to contain the copies of $x$ and $y$ and additional tapes, are reseted by $M$.

Before we can define the machine $M$, we first have to decide on which alphabet $M$ is defined.  If the machine operates on only one data type, then
we define $M$ over the smallest alphabet to encode this type on.  On the other hand, if $M$ operates on more alphabets, we use the technique in
Section~\ref{sec:extend-alphabet}.

For the verification of $M$, we first have to give the correctness relation of $\MS{Step}$.  It should encode the loop invariant as general as
possible.  Then we can define the correctness relation $LoopRel$ of $\MS{Loop}$ and prove $\MS{Loop} \Realise LoopRel$.  After that, we define runtime
relations $StepT$ and $LoopT$, and show $\MS{Step} \TerminatesIn StepT$, and after that $\MS{Loop} \TerminatesIn LoopT$.  Finally, we prove
$M \Realise FunRel(f)$ and $M \TerminatesIn FunT(steps)$, where $f:X \to Y \to Z$ is the function that $M$ computes and $steps:X \to Y \to \Nat$ the
runtime function.


\section{Case Studies}
\label{sec:case-studies}

We implement the general design of the previous section for concrete functions.

\subsection{Machines Computing Natural Functions}
\label{sec:NatTM}

We want to implement the functions $add,mult:\Nat\to\Nat\to\Nat$, according to Definition~\ref{def:Computes2_Rel}.  First we define the machine
$\MS{Add}$ that computes the addition function.  We reuse this machine to implement a machine $\MS{Mult}$ that computes the multiplication function.

\subsubsection{Addition}
\label{sec:Add}

The algorithm that our machine implements can be described with in the following pseudocode:
{
  \small
\begin{lstlisting}[style=pseudocode]
a := n
b := m
While (b--) {
  a++
}
Reset b
Return a
\end{lstlisting}
}
The output tape is the tape that is represented by the variable $a$.  First, we copy the input $n$ to this tape, and the number $m$ to an internal
tape.  In the loop, as long as we can decrease the copy of $m$, we increment $a$.  After the loop, we reset the copy $b$ and the machine terminates.
The return statement in the pseudocode above only indicates, which variable stores the result after the program terminated.  The first step in the
design of the machine is to specify, which tape contains which variable.  This is visualised in Table~\ref{tab:tapes-Add}.

\begin{table}[h]
  \centering
  \begin{tabular}{|l|l|l|l|}
    \hline
     Tape of $\MS{Add}$ & Variable & Role      & Tape in $\MS{AddStep}$ \\ \hline\hline
     $0$                & $m$      & Input     & --                     \\ \hline
     $1$                & $n$      & Input     & --                     \\ \hline
     $2$                & $a$      & Output    & $0$                    \\ \hline
     $3$                & $b$      & Internal  & $1$                    \\ \hline
  \end{tabular}
  \caption{Tape assignment for $\MS{Add}$ and $\MS{AddStep}$}
  \label{tab:tapes-Add}
\end{table}

Because the machine only works on natural numbers, we chose $SigNat$ as the alphabet of $\MS{Add}$ and all its sub-machines.

The next step is to implement the step machine.  $\MS{AddStep}$ has only access to the variables $a$ and $b$, that are stored on tape $0$ and $1$, as
also visualised in Table~\ref{tab:tapes-Add}.  The decrement operation and test whether $b$ was $0$ is implemented using the deconstructor machine
$\MS{MatchNat}$.  In the case that $b$ is $0$, the step machine terminates in $\Some\unit$, so that the loop brakes.  In case $b$ is greater then $0$,
$\MS{MatchNat}$ decreases $b$ and the step machine increases $a$.  Then it terminates in $\None$, so that the loop continues.
\begin{definition}[$\MS{AddStep}$]
  \label{def:Add_Step}
  \[
    \MS{AddStep} := \If{\LiftTapes{\MS{MatchNat}}{\Vector{1}}}{\Return{(\LiftTapes{\MS{ConstrS}}{\Vector{0}})}{\None}}{\Return{\Nop}{\Some\unit}}.
  \]
\end{definition}

Because all parts of $\MS{AddStep}$ terminate in constant time, we get the constant runtime part of the semantics of $\MS{AddStep}$ for free.
\begin{lemma}[Correctness of $\MS{AddStep}$]
  \label{lem:Add_Step_Sem}
  $\MS{AddStep} \RealiseIn{9} AddStepRel$ with
\begin{lstlisting}[style=semicoqstyle]
$AddStepRel$ :=
  $\lambda~t~(y, t').~ \forall (a~b:\Nat).$
      $t[0] \simeq a \rightarrow t[1] \simeq b \rightarrow$
      match $y$, $b$
      [ $\Some\unit$, $O$ =>
        $t'[0] \simeq a ~\land~$
        $t'[1] \simeq b$
      | $\None$, $S~b'$ =>
        $t'[0] \simeq S~a ~\land~$
        $t'[1] \simeq b'$
      | _, _ => $\False$
      ].
\end{lstlisting}
\end{lemma}

According to the general design plan, we define $\MS{AddLoop} := \While~\MS{AddStep}$.  The correctness relation of $\MS{AddLoop}$ now says, that
after the execution of the loop, $t'[0]$ contains $a+b$ and $t'[1]$ contains $0$:
\begin{lemma}[Correctness of $\MS{AddLoop}$]
  \label{lem:Add_Loop_Sem}
  $\MS{AddLoop} \Realise AddLoopRel$ with
  \[
    AddLoopRel := \lambda t~t'.~\forall (a~b:\Nat).~t[0] \simeq a \rightarrow t[1] \simeq b \rightarrow t'[0] \simeq a+b \land t'[1] \simeq 0.
  \]
\end{lemma}
\begin{proof}
  Using the $\While$-induction Lemma~\ref{lem:WhileInduction}.  In case the loop terminated, $b$ must have been $0$ and $t'[0] \simeq a$, therefore
  $t'[0]$ contains $a=a+0=a+b$.  In the induction/loop case, we know that $b=1+b'$ and that $t'[0] \simeq S~a$ and $t'[1] \simeq b'$.  By the
  inductive hypothesis, we know that $t''[0]$ contains $b' + S~a = a+b$ and $t''[1] \simeq 0$.
\end{proof}

The runtime of $\MS{AddLoop}$ must be shown separately.  We know that the loop is executed $b+1$ times, each iteration takes $9$ steps.  We have to
add $1$ step for each re-iteration of the loop.  So, the total step number is $9+10 \cdot b$.
\begin{lemma}[Runtime of $\MS{AddLoop}$]
  \label{lem:Add_Loop_TerminatesIn}
  $\MS{AddLoop} \downarrow AddLoopT$ with
  \[
    AddLoopT := \lambda t~k.~\exists (a~b:\Nat).~t[0] \simeq a \land t[1] \simeq b \land 9+10 \cdot b \leq k.
  \]
\end{lemma}

Now we can define the full machine $\MS{Add}$:
\begin{definition}[$\MS{Add}$]
  \label{def:Add}
  ~
  \[
    \MS{Add} :=
    \LiftTapes{\MS{CopyValue}}{\Vector{1;2}} \Seq
    \LiftTapes{\MS{CopyValue}}{\Vector{0;3}} \Seq
    \LiftTapes{\MS{AddLoop}}{\Vector{2;3}} \Seq
    \LiftTapes{\MS{Reset}}{\Vector{3}}.
  \]
\end{definition}

At this point, we introduce a graphical notation of execution protocols that show the value of each tape after the execution of each sub-machine.  In
the left column we have the input values for each tape, or $\dashv$ if the tape is initially right.  Each further column denotes the executions of the
(tape-lifted) sub-machines.  We write entries $j: x$ in each cell that is in the index-vector of the sub-machine.  $j$ is the tape-index of the lifted
machine and $x$ is the value after the execution of the sub-machine on this tape.  We use the symbol $\dashv$ to denote that the tape is right.  If a
cell of the table is empty, the tape has not changed, read further left in the same row.  In Table~\ref{tab:exec-Add}, we have an example of an
execution protocol for $\MS{Add}$.

\begin{table}[h]
  \centering
  \begin{tabular}{l||l|l|l|l}
    Input          & $\MS{CopyValue}$ & $\MS{CopyValue}$ & $\MS{AddLoop}$ & $\MS{Reset}$ \\ \hline
    $0$ : $m$      &                  & $0$: $m$         &                &              \\
    $1$ : $n$      & $0$: $n$         &                  &                &              \\
    $2$ : $\dashv$ & $1$: $n$         &                  & $0$: $m+n$     &              \\
    $3$ : $\dashv$ &                  & $1$: $m$         & $1$: $0$       & $0$: $\dashv$\\
  \end{tabular}
  \caption{Execution protocol of $\MS{Add}$}
  \label{tab:exec-Add}
\end{table}

From the execution protocol in Table~\ref{tab:exec-Add}, we can see that after the execution of all four sub-machines, the tapes $0$ and $1$ still
contain the values $m$ and $n$, tape $2$ contains $m+n$, and tape $3$ is right.  Execution protocols serve as outlines of the formal correctness
proofs.  We conclude the correctness of $\MS{Add}$.
\begin{lemma}[Correctness of $\MS{Add}$]
  \label{lem:Add_Computes}
  $\MS{Add} \Realise FunRel(add)$.
\end{lemma}

For the runtime function, we have to add linear components for the copying of $m$ and $n$.
\begin{lemma}[Runtime of $\MS{Add}$]
  $\MS{Add} \downarrow FunT(stepsAdd)$ with
  \[
    stepsAdd~m~n := 98 + 22 \cdot m + 12 \cdot n.
  \]
\end{lemma}

\begin{table}[h]
  \centering
  \begin{tabular}{|l|l|l|}
    \hline Sub-Machine & Runtime & Accumulated runtime \\ \hline\hline
    $\LiftTapes{\MS{CopyValue}}{\Vector{1;2}}$  & $37 + 12 \cdot n$ & $98 + 22 \cdot m + 12 \cdot n$ \\ \hline
    $\LiftTapes{\MS{CopyValue}}{\Vector{0;3}}$  & $37 + 12 \cdot m$ & $60 + 22 \cdot m$ \\ \hline
    $\LiftTapes{\MS{AddLoop}}{\Vector{2;3}}$    & $9 + 10 \cdot m$  & $22 + 10 \cdot m$ \\ \hline
    $\LiftTapes{\MS{Reset}}{\Vector{3}}$        & $12$              & $12$ \\ \hline
  \end{tabular}
  \caption{Accumulated sub-runtimes of $\MS{Add}$}
  \label{tab:runtime-Add}
\end{table}

When we prove the runtime of sequences of multiple machines, we have to give runtime functions for all suffixes of the sequence in terms of the
sequence operator.  We accumulate the runtimes from down to top and have to add one additional step for each sequence operator.  This is visualised in
Table~\ref{tab:runtime-Add}.


\subsubsection{Multiplication}
\label{sec:Mult}

\todo{Multiplication machine}


\subsection{Mapping of Sum Functions}
\label{sec:SumTM}

Let $f : X \to Z$ and $g : Y \to Z$.  Then we can define the canonical function $(f+g) : X+Y \to Z$ by
\begin{alignat*}{2}
  (f+g)&~(\inl x)&~:=~& f(x) \\
  (f+g)&~(\inr y)&~:=~& g(y).
\end{alignat*}
We want to define an operator that takes machines $M_1, M_2$ that compute the unary functions $f$ and $g$, and yields a machine $\MS{MapSum}$ that
computes the function $(f+g)$.

First we have to define precisely, which machine has which alphabet.  We want to be as general as possible.  Let $X, Y$ be encodable over
$\Sigma_X, \Sigma_Y$.  We assume $M_1, M_2 : \TM_{\Sigma_M}^{2+n}$, i.e.\ both machines have the same alphabet (if not, they can be alphabet-lifted)
and they have at least two tapes (i.e.\ an input and output tape).  We assume that $\Sigma_M$ includes $\Sigma_X$, $\Sigma_Y$, and $\Sigma_Z$.
Formally, this means that we assume retractions $f_X,f_Y,f_Z$ between $\Sigma_X, \Sigma_Y, \Sigma_Z$ and $\Sigma_M$.  Let $\Sigma$ be the alphabet for
$\MS{MapSum}$, with a retraction $f_M : \Sigma_M \hookrightarrow \Sigma$.  Furthermore, it should be possible to encode $X+Y$ on $\Sigma$, so we
assume a retraction $f_{X+Y} : \Sigma_{X+Y} \hookrightarrow \Sigma$.  We notice that there are now two possibilities how to encode $X$ (and dually
$Y$) on $\Sigma$: via the retractions $f_X \circ f_M$ and $RetrInl \circ f_{X+Y}$.  These retractions might be extensionally equal for concrete
choices of alphabets, but we want to be as general as possible.  As a consequence, we need to translate between these representations, using the
$\MS{Translate}$ machine of Section~\ref{sec:Translate}.  Note that there is only one way to encode $Z$ on $\Sigma$, namely via $f_Z \circ f_M$.

The machine $\MS{MapSum}$ first makes a case-distinction on the value $s:X+Y$ on the input tape $0$.  If it is $x$ (on the alphabet $\Sigma_{X+Y}$),
it is translated to the alphabet of $M_1$.  Then we execute the alphabet-lifted machine $M_1$.  This writes the output $f_1(x)$ on the output tape $1$
and leaves $x$ unchanged.  After that, $\MS{MapSum}$ translates $x$ back to the alphabet $\Sigma_{X+Y}$ and applies the constructor $\inl$, so the
input tape contains $\inl x$ again.  The case when the input was $s=\inl y$ is symmetric.

\begin{definition}[$\MS{MapSum}$]
  \label{def:MapSum}
  ~
  \begin{align*}
    & \MS{MapSum}~:= \\
    &\quad \MS{If}~{\LiftBoth{\MS{MatchSum}}{f_{X+Y}}{\Vector{0}}} \\
    &\quad \MS{Then}~ \LiftTapes{(\MS{Translate}~(RetrInl \circ f_{X+Y})~(f_X \circ f_M))}{\Vector{0}} \Seq \LiftAlphabet{M_1}{f_M} \Seq \\
    &\quad \phantom{\MS{Then}}~ \LiftTapes{(\MS{Translate}~(f_X \circ f_M)~(RetrInl \circ f_{X+Y}))}{\Vector{0}} \Seq \\
    &\quad \phantom{\MS{Then}}~ \LiftBoth{\MS{ConstrInl}}{f_{X+Y}}{\Vector{0}} \\
    &\quad \MS{Else}~~~ \LiftTapes{(\MS{Translate}~(RetrInr \circ f_{X+Y})~(f_Y \circ f_M))}{\Vector{0}} \Seq \LiftAlphabet{M_2}{f_M} \Seq \\
    &\quad \phantom{\MS{Then}}~ \LiftTapes{(\MS{Translate}~(f_Y \circ f_M)~(RetrInr \circ f_{X+Y}))}{\Vector{0}} \Seq \\
    &\quad \phantom{\MS{Then}}~ \LiftBoth{\MS{ConstrInr}}{f_{X+Y}}{\Vector{0}}.
  \end{align*}

% \begin{lstlisting}[style=semicoqstyle]
% $\MS{MapSum} :=$
%   $\MS{If}$ $\LiftBoth{\MS{MatchSum}}{f_{X+Y}}{\Vector{0}}$
%   $\MS{Then}$     $\LiftTapes{(\MS{Translate}~(RetrInl \circ f_{X+Y})~(f_X \circ f_M))}{\Vector{0}} \Seq \LiftAlphabet{M_1}{f_M} \Seq$
%        $\LiftTapes{(\MS{Translate}~(f_X \circ f_M)~(RetrInl \circ f_{X+Y}))}{\Vector{0}} \Seq$
%        $\LiftBoth{\MS{ConstrInl}}{f_{X+Y}}{\Vector{0}}$
%   $\MS{Else}$     $\LiftTapes{(\MS{Translate}~(RetrInr \circ f_{X+Y})~(f_Y \circ f_M))}{\Vector{0}} \Seq \LiftAlphabet{M_2}{f_M} \Seq$
%        $\LiftTapes{(\MS{Translate}~(f_Y \circ f_M)~(RetrInr \circ f_{X+Y}))}{\Vector{0}} \Seq$
%        $\LiftBoth{\MS{ConstrInr}}{f_{X+Y}}{\Vector{0}}.$
% \end{lstlisting}
\end{definition}

\begin{lemma}[Correctness of $\MS{MapSum}$]
  \label{lem:MapSum_Computes}
  If $M_1 \Realise FunRel(f_1)$ and $M_2 \Realise FunRel(f_2)$, then $\MS{MapSum} \Realise FunRel(f_1+f_2)$.
\end{lemma}


\subsection{Machines Computing Functions on Lists}
\label{sec:ListTM}


\todo{Matches and constructors of lists are missing}
\todo{Nth, (App), Length}



%%% Local Variables:
%%% TeX-master: "thesis"
%%% End:
