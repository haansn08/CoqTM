\chapter{Combining Turing Machines}
\label{chap:combining}

Recall that Turing machines are unstructured -- the execution of a machine could continue from one state to any other state of the machine.  There is
also no trivial way how to sequentially compose two machines.  We fix these problems and introduce \textit{control flow} operators, like ``if then
else'', ``sequential composition'', and ``while''.  Thus we do not need to define transition functions $\delta$ or even states $Q$ for complex
machines, because we only combine machines using these operators.  The transition function of the sequential composition of $M_1$ and $M_2$ is derived
from the transition functions of $M_1$ and $M_2$.  But maybe more importantly, this also makes correctness of machines compositional: From the
correctness of $M_1$ and $M_2$, we can conclude the correctness of the sequential composition of $M_1$ and $M_2$.  Also note that the number of
machine states can be \textit{huge} for complex machines, so it is important to not refer to any concrete machine state, either in the definition or
in the verification of a machine.\footnote{Using this framework, we define and verify a machine with 11537 states.}

We define control flow operators as \textit{first-class citizen} in Coq's type theory.  As a result, we get a \textit{shallow-embedded} language for
programming multi-tape Turing machines in an imperative way.  The primitive machines defined in Chapter~\ref{chap:basic} serve as the ``primitive
instructions'' of our language.  Another possible approach, called \textit{deep embedding}, is to define a fixed syntax of a language as an inductive
data type.  We would need a compiler from syntax trees of Turing machine programs to actual Turing machines.  This compiler would have to be extended,
whenever we add a new feature to our language.  In our approach, we can just ``extend'' our language by defining a function, and we use the same
verification technique (i.e.\ realisation and termination) on each stage of the development.


\section{$\Switch$}
\label{sec:switch}

\setCoqFilename{ProgrammingTuringMachines.TM.Combinators.Switch}

Asperti and Ricciotti~\cite{asperti2015} define the control-flow operators sequential composition, conditional, and while.  Their conditional operator
takes a concrete machine state as parameter.  We noticed that that is not acceptable for a control-flow operator.  We now introduce a generalised
operator on labelled machines, called $\MS{Switch}$, and derive sequential composition and conditional from this operator.

\begin{definition}[$\MS{Switch}~M~f$][Switch]
  \label{def:Switch}
  Let $M : \TM_\Sigma^n(L)$ and $f : L \to \TM_\Sigma^n(L')$.  We define the machine $\MS{Switch}~M~f : \TM_\Sigma^n(L')$ with the following
  components:
  \begin{alignat*}{3}
    & Q                  &~:=~& Q_M +  \sum_{l:L} Q_{f(l)} \\
    & start              &~:=~& \inl start_M \\
    \delta ~&(\inl q, s) &~:=~&
    \begin{cases}
      \bigl(\inr (lab_M~q, start_{f (lab_M~q)}), (\None, N)^n \bigr) & halt_M(q) \\
      \Let{(q', act) := \delta_M(q, s)}{\left(\inl q', act \right)} & \lnot halt_M(q)
    \end{cases} \\
    \delta ~&(\inr q, s) &~:=~& \Let{(q', act) := \delta_{f(\pi_1 q)} (\pi_2 q, s)}{\bigl( \inr (\pi_1 q, q'), act \bigr)} \\
    halt   ~&(\inl  q)   &~:=~& \false \\
    halt   ~&(\inr  q)   &~:=~& halt_{f(\pi_1~q)} (\pi_2~q) \\
    lab   ~&(\inl  q)   &~:=~& \_ \\
    lab   ~&(\inr  q)   &~:=~& lab_{f(\pi_1~q)} (\pi_2~q)
  \end{alignat*}
\end{definition}

In Definition~\ref{def:Switch}, the $lab$ value for $\inl$ is unimportant, because the lifted states of $M$ are not terminating states for
$\MS{Switch}~M~f$.  We just use a canonical value.

\begin{figure}
  \center
  \input{fig-SwitchExample}
  \caption{Example of a $\MS{Switch}$.  The left box stands for the first machine $M_1:\TM_\Sigma^n(\Bool)$.  The final states $q_1$ and $q_2$ are
    mapped to $\true$ and $q_3$ to $\false$.  After $\MS{Switch}$ reaches one of the injections of the terminal states $q_1, q_2, q_3$ of $M_1$, it
    continues its execution either in the top case machine $M_2$ or in the bottom case machine $M_3$.  The halting states of $\MS{Switch}$ are exactly
    the injections of the halting states of the case-machines.}
  \label{fig:match}
\end{figure}

$\MS{Switch}~M~f$ first executes a copy of $M$.  When it reaches a final state $q$ of $M$, it does a ``nop'' action (i.e.\ $(\None,N)^n$) and changes
to the injection of the start state of the machine $f(lab_M~q)$.  When $\MS{Switch}~M~f$ reaches a state that is the injection of a final state of a
machine $f~l$, it terminates.  The correctness lab of the semantics can be expressed using the following lemma:

\begin{lemma}[Correctness of $\MS{Switch}~M~f$][Switch_Realise]
  \label{lem:Switch_Realise}
  Let $R \subseteq \Tape_\Sigma^n \times L \times \Tape_\Sigma^n$ and $R'~l \subseteq \Tape_\Sigma^n \times L' \times \Tape_\Sigma^n$ for all $l:L$.
  If $M \Realise R$ and $f~l \Realise R'~l$ for all $l:L$, then
  \[
    \MS{Switch}~M~f \Realise SwitchRel~R~R'
  \]
  with
  \[
    SwitchRel~R~R' := \bigcup_{l:L} \bigl( R\at l \circ R'~l \bigr)
  \]
\end{lemma}

Note that in the correctness relation, we compose the unlabelled relation $R \at l \subseteq \Tape_\Sigma^n \times \Tape_\Sigma^n$ with the labelled
relation $R'~l \subseteq \Tape_\Sigma^n \times L' \times \Tape_\Sigma^n$.  This means that $\Switch~M~f$ terminates in a state with a label of $f~l$,
which has type $L'$.

To specify the running time of $\MS{Switch}~M~f$, we need to know the running time relation in that $M$ terminates, and for each $l:L$ the running
time relation of $f~l$.  We also need to know the correctness relation of $M$, because the running time of $f~l$ depends on the output of $M$, which
is the input of $f~l$.  Also, the choice of the case machine depends on the label of the terminating state of $M$.

\begin{lemma}[Running Time of $\MS{Switch}~M~f$][Switch_TerminatesIn]
  \label{lem:Switch_Terminates}
  Let $R \subseteq \Tape_\Sigma^n \times L \times \Tape_\Sigma^n$, $T \subseteq \Tape_\Sigma^n \times \Nat$, and
  $T'~l \subseteq \Tape_\Sigma^n \times \Nat$ for all $l:L$.  If $M \Realise R$, $M \TerminatesIn T$, and $f~l \TerminatesIn T'~l$ for all $l:L$, then
  $\MS{Switch}~M~f \TerminatesIn SwitchT~R~T~T'$, where
  \[
    SwitchT~R~T~T' :=
    \lambda~t~k.~ \exists~k_1~k_2.~T~t~k_1 \land 1+k_1+k_2 \le k \land
      \forall~l~t'.~ R~t~(l,t') \rightarrow T'(l)~t'~k_2
  \]
\end{lemma}

We can combine the correctness and running time lemma, in case $M$ and every $f~l$ terminates in constant time.
\begin{lemma}[Correctness of $\MS{Switch}~M~f$ in constant time][Switch_RealiseIn]
  \label{lem:Switch_RealiseIn}
  Let $k_1, k_2:\Nat$.\\
  If $M \RealiseIn{k_1} R$ and $f~l \RealiseIn{k_2} R'~l$ for every $l:L$, then
  \[ \MS{Switch}~M~f \RealiseIn{1+k_1+k_2} SwitchRel~R~R' \]
\end{lemma}
\begin{proof}
  Follows with the Lemmas~\ref{lem:Realise_total},~\ref{lem:Switch_Realise}, and~\ref{lem:Switch_Terminates}.
\end{proof}


\subsection{Derived Operators}
\label{sec:match-derived-operators}
\setCoqFilename{ProgrammingTuringMachines.TM.Combinators.SequentialComposition}%

As mentioned above, conditional and sequential composition can be defined as instances of the Switch operator.  For the sequential composition
$M_1 \Seq M_2$ with $M_1 : \TM_\Sigma^n(L)$ and $M_2 : \TM_\Sigma^n(L')$, the function $f : L \to \TM_\Sigma^n(L')$, maps all labels of $M_1$ to the
machine $M_2$.
\begin{definition}[Sequential composition][Seq]
  \label{def:Seq}
  Let $M_1 : \TM_\Sigma^n(L)$ and $M_2 : \TM_\Sigma^n(L')$ .
  \[
    M_1 \Seq M_2 := \Switch~M_1~
    \bigl(
    \lambda~\_.~M_2
    \bigr)
  \]
\end{definition}
This means that regardless in which state the machine $M_1$ terminated, the sequential composition $M_1 \Seq M_2$ continues its execution in the start
state of $M_2$.  The following lemma is the correctness lemma of sequential composition, for constant-time termination.  The version without
constant-time termination, i.e.\ the lemma we get notationally by removing the step numbers, holds as well.

\begin{lemma}[Correctness of sequential composition][Seq_RealiseIn]
  \label{lem:Seq_RealiseIn}
  If $M_1 \RealiseIn{k_1} R_1$ and $M_2 \RealiseIn{k_2} R_2$, then
  $
  M_1 \Seq M_2 \RealiseIn{1+k_1+k_2} \bigcup_{l:L} \left(R_1\at l \circ R_2 \right)
  $
\end{lemma}

We often have the case that the first machine $M_1$ is labelled over the unit-type $L = \Unit$.  In this case, the relation is
$\left(\bigcup_{l:L} R_1\at l\right) \circ R_2 \equiv R_1 \at \unit \circ R_2 = R_1 \circ R_2$ by the convention that we identify unit-labelled
relations with unlabelled relations.  This means that sequential composition of two machines amounts to composing their correctness relations.

In case either $M_1$ or $M_2$ do not have constant running time, we need the running time lemma, which can be derived from
Lemma~\ref{lem:Switch_Terminates}.
\begin{lemma}[Running Time of sequential composition][Seq_TerminatesIn]
  \label{lem:Seq_TerminatesIn}
  If $M_1 \Realise R_1$, $M_1 \TerminatesIn T_1$, and $M_2 \TerminatesIn T_2$, then
  \[
    M_1 \Seq M_2 \TerminatesIn
    \left(%
      \lambda t~k.~\exists k_1~k_2.~T_1~t~k_1 ~\land~ 1 + k_1 + k_2 \leq k ~\land~ \forall t'~l.~R_1~t~(l,t') \rightarrow T_2~t'~k_2%
    \right)
  \]
\end{lemma}


For the conditional $\If{M_1}{M_2}{M_3}$ with $M_1 : \TM_\Sigma^n(\Bool)$, $M_2, M_3 : \TM_\Sigma^n(L)$, the function $f : \Bool \to \TM_\Sigma^n(L)$
simply maps $\true$ to $M_2$ and $\false$ to $M_3$.  The conditional, as defined below, first executes $M_1$.  If terminated in a state with label
$\true$, it continues the execution in $M_2$, else in $M_3$.

\setCoqFilename{ProgrammingTuringMachines.TM.Combinators.If}%
\begin{definition}[Conditional][If]
  \label{def:If}
  Let $M_1 : \TM_\Sigma^n(\Bool)$, $M_2, M_3 : \TM_\Sigma^n(L)$.
  \[
    \If{M_1}{M_2}{M_3} := \Switch~M_1~
    \left(\lambda b.~\cond{b}{M_2}{M_3} \right)
  \]
\end{definition}

\begin{lemma}[Correctness of conditional][If_RealiseIn]
  \label{lem:If_RealiseIn}
  If $M_1 \RealiseIn{k_1} R_1$, $M_2 \RealiseIn{k_2} R_2$, and $M_3 \RealiseIn{k_3} R_3$, then
  $
    \If{M_1}{M_2}{M_3} \RealiseIn{1+k_1+max(k_2+k_3)} (R_1\at\true \circ R_2) \cup (R_1\at\false \circ R_3)
  $
\end{lemma}

The correctness relation $(R_1\at\true \circ R_2) \cup (R_1\at\false \circ R_3)$ captures the idea of the following case-distinction: If the
conditional machine terminated, than the copy of $M_1$ either terminated in a state with label $\true$ or $\false$.  In the first case, the
conditional proceeded in $M_2$, else in $M_3$.

The running time lemma of the conditional can also be derived from Lemma~\ref{lem:Switch_Terminates}.
\begin{lemma}[Running Time of the conditional][If_TerminatesIn]
  \label{lem:If_TerminatesIn}
  If $M_1 \Realise R_1$, $M_1 \TerminatesIn T_1$, $M_2 \TerminatesIn T_2$, and $M_3 \TerminatesIn T_3$, then
  \begin{align*}
    & \If{M_1}{M_2}{M_3} \TerminatesIn \\
    &\quad \bigl( \lambda t~k.~\exists k_1~k_2.~T_1~t~k_1 ~\land~ 1+k_1+k_2 \leq k ~\land~ \\
    &\quad \phantom{\bigl( \lambda t~k.~\exists k_1~k_2.}~\forall b~t'.~R_1~t~(b, t') \rightarrow \cond{b}{T_2~t'~k_2}{T_3~t'~k_2} \bigr)
  \end{align*}
\end{lemma}


Asperti and Ricciotti~\cite{asperti2015} also define sequential composition and a conditional operator.  However, they have two fundamental
differences.  First, they define and verify each operator separately.  Secondly, they do not consider state labelling.  Their conditional operator
takes one concrete ``negative'' state, i.e.\ the machine $M_3$ is only executed if $M_1$ terminated in this particular state.  This makes programming
and reasoning about concrete machines tedious, because complex machines also have many states.  They also have to introduce a separate notion for
correctness, because they do not have states in their original one.  By introducing state-labelled machines and by implementing the more general
$\Switch$ combinator, we solve both problems.  We no longer have to specify concrete machine states in the definition and verification of machines.
Moreover, we often exploit the convenient generality of the $\Switch$ operator.  For example, it can be used to implement a machine that copies a
symbol from one tape to another tape, as demonstrated in Chapter~\ref{chap:combining}.  Also note, that Asperti and Ricciotti~\cite{asperti2015} have
no notion of time complexity; their strong notion of realisation only implies termination in an uncertain number of steps.  The idea of
state-labelling and $\Switch$ is due to Y.~Forster.


\subsection{Proof of $\Switch$}
\label{sec:match-proofs}

\setCoqFilename{ProgrammingTuringMachines.TM.Prelim}

The idea of the proofs of Lemma~\ref{lem:Switch_Realise} and Lemma~\ref{lem:Switch_Terminates} is to abstract two features of the machine: lifting of
configurations from one abstract machine to another abstract machines, and sequencing of two executions.  We formalise these two concepts for abstract
machines, i.e.\ we argue on the abstract $\Loop$ function.

For the first feature, \textit{lifting}, we assume two types $A$, $B$ for abstract configurations, a function $lift : A \to B$, two step functions
$f : A \to A$, $f' : B \to B$, and two halting functions $h : A \to \Bool$, $h' : B \to \Bool$.  We assume that the step functions $f$ and $f'$ are
compatible with $lift$ in non-halting states of $A$.  Formally, this means
\begin{equation}
  \label{eq:loop_lift_assumption1}
  \forall a:A.~\lnot h(x) \rightarrow f' (lift~x) = lift (f~x)
\end{equation}

The second assumption is that $h'$ and $h$ are compatible w.r.t.\ $lift$; formally:
\begin{equation}
  \label{eq:loop_lift_assumption2}
  \forall a:A.~h'(lift~x)=h(x)
\end{equation}

Under these two assumptions we can show two lemmas that essentially say that the second abstract machine $B$ simulates the first machine $A$.
\begin{lemma}[Loop lifting][loop_lift]
  \label{lem:loop_lift}
  Under the assumptions~(\ref{eq:loop_lift_assumption1}) and~(\ref{eq:loop_lift_assumption2}):
  \begin{alignat*}{1}
    & \forall (k:\Nat)~(a~a' : A). \\
    & \quad \Loop~f ~h ~a        ~k = \Some{a'} \rightarrow \\
    & \quad \Loop~f'~h'~(lift~a) ~k = \Some {lift~a'}
  \end{alignat*}
\end{lemma}
\begin{proof}
  By induction on $k:\Nat$.
\end{proof}
\begin{lemma}[Loop unlifting][loop_unlift]
  \label{lem:loop_unlift}
  Under the assumptions~(\ref{eq:loop_lift_assumption1}) and~(\ref{eq:loop_lift_assumption2}):
  \begin{alignat*}{1}
    & \forall (k:\Nat)~(a:A)~(b':B). \\
    & \quad \Loop~f'~h'~(lift~a)~k = \Some{b'} \rightarrow \\
    & \quad \exists (a':A).~\Loop~f~h~a~k = \Some{a'} \land b'=lift~a'
  \end{alignat*}
\end{lemma}
\begin{proof}
  By induction on $k:\Nat$.
\end{proof}

\begin{figure}
  \center
  \begin{tikzcd}
    a'                    \arrow[r, "lift"] & \cdot \\
    \cdot \arrow[u, "f"]  \arrow[r, "lift"] & \cdot \arrow[u, "g", swap] \\
    a     \arrow[u, "f"]  \arrow[r, "lift"] & \cdot \arrow[u, "g", swap] \\
  \end{tikzcd}
  \hspace{1cm}
  \begin{tikzcd}
    a'                            \arrow[r, "lift", dotted] & b' \\
    \cdot \arrow[u, "f", dotted]  \arrow[r, "lift", dotted] & \cdot \arrow[u, "g", swap] \\
    a     \arrow[u, "f", dotted]  \arrow[r, "lift"]         & \cdot \arrow[u, "g", swap] \\
  \end{tikzcd}
  \caption{Instances of Lemma~\ref{lem:loop_lift} (left) and Lemma~\ref{lem:loop_unlift} (right) for $k=2$ as commuting diagrams.  Dotted lines denote
    existentials.  Note that the rectangles correspond to condition (\ref{eq:loop_lift_assumption1}).  Only the top ``states'' are terminating
    states.}
  \label{fig:loop_lift_lemmas}
\end{figure}

The Lemmas~\ref{lem:loop_lift} and~\ref{lem:loop_unlift} are visualised in Figure~\ref{fig:loop_lift_lemmas}.

For the second feature, \textit{sequential execution}, we assume another type $A$ with a step function $f \from A \to A$ and two halting functions
$h, h' \from A \to \Bool$.  We assume, that if $a$ is a halting state w.r.t.\ $h$, then $a$ also is a halting state w.r.t.\ $h'$:
\begin{equation}
  \label{eq:loop_merge_assumption}
  \forall(a:A).~h~a = \false \rightarrow h'~a = \false
\end{equation}

\begin{lemma}[Loop merging][loop_merge]
  \label{lem:loop_merge}
  Under assumption~(\ref{eq:loop_merge_assumption}):
  \begin{align*}
    & \forall (k_1~k_2:\Nat)~(a_1~a_2~a_3 : A).\\
    & \quad \Loop~f~h ~a_1~k_1       = \Some{a_2} \rightarrow\\
    & \quad \Loop~f~h'~a_2~k_2       = \Some{a_3} \rightarrow\\
    & \quad \Loop~f~h'~a_1~(k_1+k_2) = \Some{a_3}
  \end{align*}
\end{lemma}
\begin{proof}
  By induction on $k_1:\Nat$, using Lemma~\ref{lem:loop}~(\ref{lem:loop_monotone}).
\end{proof}
\begin{lemma}[Loop splitting][loop_split]
  \label{lem:loop_split}
  Under assumption~(\ref{eq:loop_merge_assumption}):
  \begin{align*}
    & \forall (k:\Nat)~(a_1~a_3 : A).\\
    & \quad \Loop~f~h'~a_1~k = \Some{a_3} \rightarrow \\
    & \quad \exists (k_1~k_2:\Nat)~(a_2:A).\\
    & \quad \quad \Loop~f~h ~a_1~k_1 = \Some{a_2} \land\\
    & \quad \quad \Loop~f~h'~a_2~k_2 = \Some{a_3} \land\\
    & \quad \quad k_1 + k_2 \leq k
  \end{align*}
\end{lemma}
\begin{proof}
  By complete induction on $k:\Nat$.
\end{proof}


Back to the verification of $\Switch~M~f$.  In the following, we simply write $\Switch$.  For a configuration $c_k$, we write $q_k$ and $t_k$ for the
state and tapes component of $c_k$.

The execution steps of $\Switch$ are essentially a sequence of first, the lifted steps of execution of $M$, second, a ``nop'' transition, and third,
the lifted steps of the execution of $f~l$.  We give the concrete lifting functions from $M$ to $\Switch$ and from $M~l$ to $\Switch$:
\setCoqFilename{ProgrammingTuringMachines.TM.Combinators.Switch}%
\begin{definition}[Liftings of $\Switch$][lift_confL]
  We define the functions \\$liftL : \Conf_M \to \Conf_\Switch$ and $liftR_l : \Conf_{f(l)} \to \Conf_\Switch$ for all $l:L$:
  \begin{alignat*}{2}
    & liftL   & (q, t) &:= (\inl q,      t) \\
    & liftR_l & (q, t) &:= (\inr (l, q), t)
  \end{alignat*}
\end{definition}

For the sequential lab, we also have to define the lifted halting function of \\$haltConfL : \Conf_\Switch \to \Bool$:
\begin{definition}[Lifted halting function][halt_liftL]
  \begin{alignat*}{2}
    & haltConfL & (\inl~q, t) &:= halt_M(q) \\
    & haltConfL & (\inr~q, t) &:= \true
  \end{alignat*}
\end{definition}

Using Lemma~\ref{lem:loop_merge} and~\ref{lem:loop_lift}, we can show the lemma we need for running time:
\begin{lemma}[Merging parts of executions of $\Switch$][Switch_merge]
  \label{lem:Switch_merge}
  Let $t : \Tape_\Sigma^n$, $k_1, k_2:\Nat$, $c_1 : \Conf_M$ and $c_2 : \Conf_{f(lab_M~q_1)}$.
  \begin{alignat*}{1}
    & M(t) \terminates^{k_1} c_1 \rightarrow\\
    & \bigl( f~(lab_M~q_1) \bigr) (t_1) \terminates^{k_2} c_2 \rightarrow\\
    & \Switch(t) \terminates^{1+k_1+k_2} liftR(c_2)
  \end{alignat*}
\end{lemma}
\begin{proof}
  We apply Lemma~\ref{lem:loop_merge} and have to show:
  \begin{enumerate}
  \item $\forall a:\Conf_\Switch.~ \lnot haltConfL~a \rightarrow \lnot \MS{haltConf}~a$.  This holds trivially by case-analysis over $a$.
  \item $\Loop~step_\Switch~haltConfL~(\MS{initConf}_\Switch~t)~k_1 =
    \Some{liftL~c_1}$.  By definition, we have $\MS{initConf}_\Switch~t=liftL(\MS{initConf}_M~t)$.  The claim follows with Lemma~\ref{lem:loop_lift}.
  \item $\Loop~step_\Switch~haltConf_\Switch~(liftL~c1)~(1+k_2) =
    \Some{liftR(c_2)}$.  By definition, we know that the first step must be a ``nop'' transition from
    $liftL~c_1$ to\\
    $liftR~\bigl(\MS{initConf}_{f(lab_M~q_1)}~t_1 \bigr)$.  It remains to show that
    $$\Loop~step_\Switch~haltConf_\Switch~liftR \bigl(\MS{initConf}_{f(lab_M~q_1)}~t_1 \bigr)~k_2 = \Some{liftR(c_2)}$$
    This follows with Lemma~\ref{lem:loop_merge}.
  \end{enumerate}
\end{proof}
The running time Lemma~\ref{lem:Switch_Terminates} follows directly from Lemma~\ref{lem:Switch_merge}.

\begin{lemma}[Splitting execution of $\Switch$][Switch_split]
  \label{lem:Switch_split}
  Let $t : \Tape_\Sigma^n$, $k : \Nat$, $c : \Conf_\Switch$.
  \begin{align*}
    & \Switch(t) \terminates^k c \rightarrow \\
    & \exists (k_1~k_2 : \Nat)~(c_1 : \Conf_M)~(c_2 : \Conf_{f(lab_M~q_1)}). \\
    & \quad M(t) \terminates^{k_1} c_1 ~\land~ \\
    & \quad \bigl( f (lab_M~q_1) \bigr) (t_1) \terminates^{k_2} c_2 ~\land~ \\
    & \quad c = liftR(c_2)
  \end{align*}
\end{lemma}
\begin{proof}
  Analogous to the proof of Lemma~\ref{lem:Switch_merge}, using Lemmas~\ref{lem:loop_split} and~\ref{lem:loop_unlift}.
\end{proof}
The correctness Lemma~\ref{lem:Switch_Realise} follows directly from Lemma~\ref{lem:Switch_split}.


Asperti and Ricciotti~\cite{asperti2015} have a version of Lemma~\ref{lem:loop_lift} and Lemma~\ref{lem:loop_merge}.

\section{$\MS{While}$}
\label{sec:While}
\setCoqFilename{ProgrammingTuringMachines.TM.Combinators.While}%

The machine $\While~M$ essentially behaves like a ``do-while'' loop in imperative languages like C.  At the end of the execution of the loop body $M$,
$M$ decides either to continue or break out of the loop.  If $M$ terminated in a state with label $\None$, then the loop is continued, and if $M$
terminated in $\Some{l}$, the loop breaks and $\While~M$ terminates in a state with label $l$.  When $M : \TM_\Sigma^n(\Option(L))$, then
$\While~M : \TM_\Sigma^n(L)$.

\begin{definition}[$\MS{While}~M$][While]
  \label{def:While}
  Let $M : \TM_\Sigma^n(\Option(L))$ and $def:L$.  We define $\MS{While}~M : \TM_\Sigma^n(L)$ with the following components.
  \begin{alignat*}{3}
    & Q              &~:=~& Q_M \\
    & start          &~:=~& start_M \\
    \delta ~& (q, s) &~:=~&
    \begin{cases}
      (start_M, (\None, N)^n) & halt_M(q) \\
      \delta_M (q,s)    & \lnot halt_M(q)
    \end{cases} \\
    halt ~& q      &~:=~& halt_M(q) \land lab_M(q) \neq \None \\
    lab ~& q      &~:=~&
    \begin{cases}
      l   & lab_M(q) = \Some l \\
      def & lab_M(q) = \None
    \end{cases}
  \end{alignat*}
\end{definition}

\begin{figure}
  \center
  \input{fig-WhileExample}
  \caption{Example for $\While~M$ with $M:\TM_\Sigma^n(\Option(\Bool))$.  When $M$ reaches the state $q_1$, the loop is continued, because $q_1$ is in
    assumed to have label $\None$.  $q_2$ and $q_3$ have the labels $\Some{\true}$ and $\Some{\false}$.  Therefore $\While~M$ terminates in a state
    with label $\true$ or $\false$, when $M$ terminated in $q_2$ or $q_3$, respectively.}
  \label{fig:while-example}
\end{figure}

In Definition~\ref{def:While}, we have to assume that $L$ is inhabited.  However, the choice of $def:L$ is semantically irrelevant, because $\While~M$
only halts in states where $lab_M(q) \neq \None$.

The correctness of $\MS{While}$ can be expressed using the following lemma:

\begin{lemma}[Correctness of $\MS{While}$][While_Realise]
  \label{lem:While_Realise}
  Let $R \subseteq \Tape_\Sigma^n \times \Option(L) \times \Tape_\Sigma^n$.
  If $M \Realise R$, then $\While~M \Realise WhileRel~R$, where
  $WhileRel~R \subseteq \Tape_\Sigma^n \times L \times \Tape_\Sigma^n$
  is inductively defined by the following two rules:
  \[
    \inferrule{R~t~(\Some{l}, t')}{WhileRel~R~t~(l, t')}
    \quad
    \inferrule{R~t~(\None, t') \and WhileRel~R~t'~(l, t'')}{WhileRel~R~t~(l, t'')}
  \]
\end{lemma}

We can also express the correctness relation of $\While$ using the Kleene star:
\begin{fact}[Alternative correctness relation for $\While~M$][OtherWhileRel]
  ~
  \[
    WhileRel~R \equiv (R \at \None)^* \circ \Bigl( \bigcup_{l:L} \bigl( R \at {\Some{l}} \bigr) \att l \Bigr)
  \]
\end{fact}

Both definitions of $WhileRel$ should make clear what $\While~M$ does: It repeats the execution of $M$ as long as it terminated in $\None$, and after
$M$ terminated in $\Some{l}$, $\While~M$ terminates in a state with label $l$.  This is visualised in Figure~\ref{fig:while-example}.  The inductive
definition is more practical when we prove correctness of concrete $\MS{While}$ machines, because we can just do induction on the inductive predicate.

When we want to prove $\While~M \Realise R$ for some machine $M:\TM_\Sigma^n(L)$ and relation
$R \subseteq \Tape_\Sigma^n \times L \times \Tape_\Sigma^n$, we must of course have already proven that $M \Realise R'$ for some relation
$R' \subseteq \Tape_\Sigma^n \times \Option(L) \times \Tape_\Sigma^n$.  Then we apply Lemma~\ref{lem:Realise_monotone} and~\ref{lem:While_Realise},
and have to show $WhileRel~R' \subseteq R$.  We can prove this by induction on the inductive predicate, which is equivalent to applying the following
lemma:
\begin{lemma}[Induction for $WhileRel$][WhileInduction]
  \label{lem:WhileInduction}
  ~
  \begin{alignat*}{1}
    & \left(\forall t~t'~l.~R'~t~(\Some{l}, t') \rightarrow R~t~(l,t')\right) \rightarrow \\
    & \left(\forall t~t'~t''~l.~R'~t~(\None, t') \rightarrow R~t'~(l, t'') \rightarrow R~t~(l,t'')\right) \rightarrow \\
    & WhileRel~R' \subseteq R
  \end{alignat*}
\end{lemma}


The running time lemma of $\While$ is dual.  We define a co-inductive termination relation $WhileT~R~T$, where $R$ is the relation that $M$ realises
and $T$ is the running time relation in that $M$ terminates.
\begin{lemma}[Running Time of $\While~M$][While_TerminatesIn]
  \label{lem:While_TerminatesIn}
  If $M \Realise R$ and $M \TerminatesIn T$.  Then $\While~M \TerminatesIn WhileT~R~T$, where $WhileT~R~T \subseteq \Tape_\Sigma^n \times \Nat$ is
  defined as the following co-inductive running time relation:
  \[
    \inferrule{T~t~k_1 \\
      \forall t'~l.~R~t~(\Some{l}, t') \rightarrow k_1 \leq k \\
      \forall t'.~R~t~(\None,t') \rightarrow \exists k_2.~WhileT~R~T~t'~k_2 \land 1+k_1+k_2 \leq k}%
    {WhileT~R~T~t~k}
  \]
\end{lemma}

When we want to show $\While~M \TerminatesIn T$, this is dual to showing $\While~M \Realise R$.  We apply the anti-monotonicity
Lemma~\ref{lem:TerminatesIn_monotone} and the above running time lemma, and have to show $T \subseteq WhileT~R~T'$.  For that, we use the co-induction
lemma of $WhileT$:
\begin{lemma}[$WhileT$ co-induction][WhileCoInduction]
  \label{lem:WhileCoInduction}
  To show $T \subseteq WhileT~R~T'$, it suffices to show:
  \begin{alignat*}{1}
    &\forall t~k.~T~t~k \rightarrow \\
    &\quad \exists k_1.~T'~t~k_1 ~\land~ \\
    &\quad\quad \left( \forall l~t'.~R~t~(\Some{l}, t') \rightarrow k_1 \leq k \right) ~\land~ \\
    &\quad\quad \left( \forall t'.~R~t~(\None, t') \rightarrow \exists k_2.~T~t'~k_2 ~\land~ 1+k_1+k_2 \leq k \right).
  \end{alignat*}
\end{lemma}
The number $k_1$ is the number of steps needed for the first iteration of the loop.  We have to consider all possible outputs of the first loop.  If
$M$ terminated in label $\Some{l}$ in $k_1$ steps, then $\While~M$ also only needs $k_1$ steps.  However, if $M$ terminated in $\None$, and $\While~M$
needs $k_2$ steps for all other loops, then $\While~M$ needs $1+k_1+k_2$ steps in total.  The one additional step comes from the ``nop''-transition
back to the starting state.



\subsection{Proof of $\While$}
\label{sec:while-proofs}

The running time and correctness proofs are similar to the proofs of $\Switch$, as explained in Section~\ref{sec:match-proofs}.  The configurations of
$\Switch$ are exactly the configurations of $M$, so the lifting function is the identity function.  However, the fundamental difference between
$\Switch$ and $\While$ is that $\While$ can execute $M$ arbitrary often.  As a consequence, we also need complete induction on step-numbers, in
addition to the loop-splitting and loop-merging lemmas.  We present the key lemmas here and the most important parts of the proofs.

We simply write $\While$ instead of $\While~M$ in this section.  Since we have $\Conf_M = \Conf_\While$, we also only write $\Conf$.

The first lemma says that an execution of $\While$ consists of an execution of $M$ and a (possibly empty) continuation of $\While$:
\begin{lemma}[Splitting the execution of $\While$][While_split]
  \label{lem:While_split}
  Let $c_1, c_3 : \Conf$ and $k:\Nat$.  Then
  \begin{alignat*}{1}
    & \While(c_1) \terminates^k c_3 \rightarrow \\
    & \exists (k_1~k_2 : \Nat)~c_2. \\
    & \quad M(c_1) \terminates^{k_1} c_2 ~\land~ \\
    & \quad \While(c_2) \terminates^{k_2} c_3 ~\land~\\
    & \quad k_1 + k_2 \leq k
  \end{alignat*}
\end{lemma}
\begin{proof}
  Follows with Lemma~\ref{lem:loop_split} and Lemma~\ref{lem:loop_lift}.
\end{proof}

We have two more splitting lemmas, one for the case that $\While$ terminated immediately, and one for the case that $\While$ continued the loop.
\begin{lemma}[Splitting, break case][While_split_term]
  \label{lem:While_split_term}
  Let $c_1$, $c_2 : \Conf$, $k:\Nat$, and $l:L$.
  \begin{alignat*}{1}
    & \While(c_1) \terminates^k c_2 \rightarrow \\
    & haltConf_M~c_1 \rightarrow \\
    & lab_M(q_1) = \Some l \rightarrow \\
    & c_1 = c_2
  \end{alignat*}
\end{lemma}
\begin{proof}
  By Lemma \ref{lem:loop} (\ref{lem:loop_eq_0}), because $c_1$ is a halting state of $\While$.
\end{proof}
\begin{lemma}[Splitting, continue case][While_split_repeat]
  \label{lem:While_split_repeat}
  Let $c_1$, $c_2 : \Conf$, $k:\Nat$.
  \begin{alignat*}{1}
    & \While(c_1) \terminates^k c_2 \rightarrow \\
    & haltConf_M~c_1 \rightarrow \\
    & lab_M(q_1) = \None \rightarrow \\
    & \exists k'.~k = 1+k' ~\land~ \While(t_1) \terminates^{k'} c_2
  \end{alignat*}
\end{lemma}
\begin{proof}
  $\While$ must have taken the ``nop''-transition from $c_1$ to $initConf~t_1$, because $c_1$ is a halting configuration of $M$ but not of $\While$.
\end{proof}

We now can prove the correctness Lemma~\ref{lem:While_Realise} of $\While$.
\begin{proof}
  We assume $\While(t_1) \terminates^k c_3$ and have to show $WhileRel~t_1~(lab_\While~q_3, t_3)$.  We use complete induction on $k:\Nat$.  By
  Lemma~\ref{lem:While_split}, we have $M(t_1) \terminates^{k_1} c_2$ and\\ $\While(c_2) \terminates^{k_2} c_3$, for $k_1+k_2 \leq k$.  Case analysis.
  \begin{enumerate}
  \item $lab_M(q_2) = \Some{l}$.  Then we know by Lemma~\ref{lem:While_split_term}, that $c_2=c_3$.  It remains to show $WhileRel~t_1~(l, t_2)$.  By
    applying the first constructor, it is enough to show $R~t_1~(\Some{l}, t_2)$.  This follows from the realisation of $M$.
  \item $lab_M(q_2) = \None$.  By Lemma~\ref{lem:While_split_repeat}, we know that $\While(t_2) \terminates^{k'_2} c_3$ for $k_2 = 1 + k'_2$.  The
    inductive hypothesis gives $WhileRel~t_2~(lab_\While~q_3, t_3)$.  The goal follows by applying the second constructor and the realisation of $M$.
  \end{enumerate}
\end{proof}


For the running time proofs, we again have lemmas that ``merge'' executions together.

\begin{lemma}[Merging, break case][While_merge_term]
  Let $k : \Nat$, $c_1, c_2 : \Conf$, and $l:L$.
  \begin{alignat*}{1}
    & M(c_1) \terminates^k c_2 \rightarrow \\
    & lab_M(q_2) = \Some{l} \rightarrow \\
    & \While(c_1) \terminates^k c_2
  \end{alignat*}
\end{lemma}
\begin{lemma}[Merging, continue case][While_merge_repeat]
  Let $k_1, k_2 : \Nat$, $c_1, c_2, c_3 : \Conf$.
  \begin{alignat*}{1}
    & M(c_1) \terminates^{k_1} c_2 \rightarrow \\
    & lab_M(q_2) = \None \rightarrow \\
    & \While(t_2) \terminates^{k_2} c_3 \rightarrow \\
    & \While(c_1) \terminates^{1+k_1+k_2} c_3
  \end{alignat*}
\end{lemma}

The running time Lemma~\ref{lem:While_TerminatesIn} follows similarly, by complete induction on $k:\Nat$.



\section{$\MS{Mirror}$}
\label{sec:mirror}

We can define a machine operator that ``mirrors'' a machine $M$.  Whenever $M$ makes a transition with a move to $L$, $\MS{Mirror}~M$ moves the head
to the right instead.  For example, we define a machine $\MS{MoveToSymbol}$ below, that moves the head of the tape right, until it reads a certain
symbol.  Using this operator, we get a machine ``for free'' that moves the head to the left instead.  However, we still have to copy or parametrise
the correctness and running time relations.

\setCoqFilename{ProgrammingTuringMachines.TM.TM}%
Using the proving techniques developed in the previous sections, verifying the $\MS{Mirror}$ operator is very easy.  The function
$\coqlink[mirror_tape]{\MS{mirror}} : \Tape_\Sigma \to \Tape_\Sigma$ swaps the left and right lab of a tape.  %
% \begin{definition}[Mirror tape][mirror_tape]
%   \label{def:mirror_tape}
%   Let $t : \Tape_\Sigma$.
%   \begin{alignat*}{2}
%     & \MS{mirror}~(\MS{niltape})         &&~:=~ \MS{niltape} \\
%     & \MS{mirror}~(\MS{leftof}~l~ls)     &&~:=~ \MS{rightof}~l~ls \\
%     & \MS{mirror}~(\MS{rightof}~l~ls)    &&~:=~ \MS{leftof}~l~ls \\
%     & \MS{mirror}~(\MS{midtape}~ls~m~rs) &&~:=~ \MS{midtape}~rs~m~ls
%   \end{alignat*}
% \end{definition}
% \begin{lemma}[Correctness of $\MS{mirror}$]
%   \label{lem:mirror}
%   Let $t:\Tape_\Sigma$.
%   \begin{enumerate}
%   \coqitem[mirror_tape_injective] \label{lem:mirror_tape_injective}
%     $\MS{mirror}$ is injective,
%   \coqitem[mirror_tape_involution] \label{lem:mirror_tape_involution}
%     $\MS{mirror}$ is an involution, i.e.\ $\MS{mirror}(\MS{mirror}(t))=t$,
%   \coqitem[mirror_tape_left] \label{lem:mirror_left}
%     $\MS{left}(\MS{mirror}(t)) = \MS{right}(\MS{mirror}(t))$,
%   \coqitem[mirror_tape_right] \label{lem:mirror_right}
%     $\MS{right}(\MS{mirror}(t)) = \MS{left}(\MS{mirror}(t))$,
%   \coqitem[mirror_tape_current] \label{lem:mirror_current}
%     $\MS{current}(\MS{mirror}(t)) = \MS{current}(t)$.
%   \end{enumerate}
% \end{lemma}
% % \begin{proof}
% %   By case analysis over the tape(s).
% % \end{proof}
Furthermore, we assume an injective and involutive function $\coqlink[mirror_move]{\MS{swap}}:\MS{Move} \to \MS{Move}$ that simply swaps the movements
$L$ and $R$.  \setCoqFilename{ProgrammingTuringMachines.TM.Combinators.Mirror}%
\begin{definition}[$\MS{Mirror}~M$][Mirror]
  \label{def:Mirror}
  Let $M:\TM_\Sigma^n(L)$.  The machine $\MS{Mirror}~M : \TM_\Sigma^n(L)$ has the same components as $M$, except:
  \[
    \delta(q, s) :=~ \Let{(q', a) := \delta_M(q,s)}{\bigl(q', \map{(\lambda(w, m).~(w, \MS{swap}(m)))}{a} \bigr)}
  \]
\end{definition}

The correctness and termination proofs are similar to the proofs of $\MS{Switch}$ and $\MS{While}$.  The ``lifting'' between configurations of $M$ and
$\MS{Mirror}$ is the injective and involutive function $mirrorConf : \Conf \to \Conf$ that simply mirrors the tapes.

\begin{definition}[Mirror configuration][mirrorConf]
  \label{def:mirrorConf}
  $mirrorConf(q,t) := (q, \map{\MS{mirror}}{t}).$
\end{definition}


\begin{lemma}[Mirroring steps][mirror_step]
  \label{lem:mirror_step}
  Let $c_1 : \Conf$.  Then
  \[ step_M~(mirrorConf~c_1) = mirrorConf~(step_{\MS{Mirror}}~c_1) \]
\end{lemma}

\begin{lemma}[Mirroring executions]
  \label{lem:mirror_loop}
  Let $c_1, c_2 : \Conf$.
  \begin{enumerate}
  \item \label{lem:mirror_lift}
    \coqlink[mirror_lift]{$\MS{Mirror} (c_1) \terminates^k c_2 \rightarrow M (mirrorConf~c_1) \terminates^k (mirrorConf~c_2)$}
  \item \label{lem:mirror_unlift}
    \coqlink[mirror_unlift]{$M (mirrorConf~c_1) \terminates^k (mirrorConf~c_2) \rightarrow \MS{Mirror} (c_1) \terminates^k c_2$}
  \end{enumerate}
\end{lemma}
\begin{proof}
  Claim~\ref{lem:mirror_lift} follows with Lemma~\ref{lem:loop_lift} and Lemma~\ref{lem:mirror_step}.  Claim~\ref{lem:mirror_unlift} follows with
  Lemma~\ref{lem:loop_unlift} and Lemma~\ref{lem:mirror_step}.
\end{proof}

\begin{lemma}[Correctness of $\MS{Mirror}$]
  Let $M \Realise R$.  Then $\MS{Mirror}~M \Realise MirrorRel~R$ with
  \[
    MirrorRel~R := \lambda t~(l, t').~ R~(\map{\MS{mirror}}{t})~(l, \map{\MS{mirror}}{t'})
  \]
\end{lemma}
\begin{proof}
  Follows from Lemma~\ref{lem:mirror_loop}~(\ref{lem:mirror_lift}).
\end{proof}
\begin{lemma}[Running Time of $\MS{Mirror}$]
  Let $M \TerminatesIn T$.  Then $\MS{Mirror}~M \TerminatesIn MirrorT~T$ with
  \[
    MirrorT~T := \lambda t~k.~ T~(\map{\MS{mirror}}{t})~k
  \]
\end{lemma}
\begin{proof}
  Follows from Lemma~\ref{lem:mirror_loop}~(\ref{lem:mirror_unlift}).
\end{proof}

\section{Relabelling Operators}
\label{sec:labelling-op}
\setCoqFilename{ProgrammingTuringMachines.TM.Combinators.Combinators}%

The operators of the above sections of this Chapter modify the behaviour of the machine.  We can also define simple operators that modify the
labelling function $lab : Q_M \to L$.  This is for example useful if we want a machine to terminate in one particular label.

\begin{definition}[$\MS{Relabel}$][Relabel]
  Let $M:\TM_\Sigma^n(L)$ and $g : L \to L'$.
  \[
    \MS{Relabel}~M~g := \left(M, g \circ lab_M\right)
  \]
\end{definition}

\begin{definition}[$\MS{Return}$][Return]
  Let $M:\TM_\Sigma^n(L)$ and $l':L'$.
  \[
    \MS{Return~M~l'} := \MS{Relabel}~M~(\lambda \_.~l')
  \]
\end{definition}

The correctness for these simple operators is obvious.  Note that we do not need lemmas for running time, because Definition~\ref{def:TerminatesIn} of
running time is defined over the bare machine without label function.  So the running time lemmas for $M$ also apply for $\MS{Relabel}$
and $\MS{Return}$.
\begin{lemma}[Correctness of $\MS{Relabel}$ and $\MS{Return}$][Relabel_Realise]
  If $M \Realise R$, then
  \begin{alignat*}{1}
    \MS{Relabel}~M~g & \Realise \bigcup_{l:L} \left( \left(R \at l\right) \att {g(l)} \right) \\
    \MS{Return}~M~l'         & \Realise \Bigl( \bigcup_{l:L} R \at {l} \Bigr) \att {l'}
  \end{alignat*}
\end{lemma}


%%% Local Variables:
%%% TeX-master: "thesis"
%%% End:
